{"cells": [{"cell_type": "markdown", "metadata": {"id": "uDdFsXXMY2xz"}, "source": ["<!-- JPN -->\n", "# \u7dcf\u5408\u6f14\u7fd2"]}, {"cell_type": "markdown", "metadata": {"id": "fVWFK95Enwtw"}, "source": ["<!-- ENG -->\n", "# Comprehensive exercise"]}, {"cell_type": "markdown", "metadata": {"id": "6wynwCYM5nQf"}, "source": ["<!-- JPN -->\n", "\u6388\u696d\u3067\u306f\u4e3b\u306b\u5206\u985e\u554f\u984c\u3092\u53d6\u308a\u6271\u3063\u3066\u304d\u305f\u304c\u3001\u3053\u306e\u8ab2\u984c\u3067\u306f\u56de\u5e30\u554f\u984c\u306b\u53d6\u308a\u7d44\u3080\u3053\u3068\u3067\u5404\u7a2e\u306e\u624b\u6cd5\u304c\u5206\u985e\u554f\u984c\u3067\u306f\u306a\u304f\u56de\u5e30\u554f\u984c\u306b\u3082\u9069\u7528\u3067\u304d\u308b\u3053\u3068\u3092\u7406\u89e3\u3057\u3066\u304a\u304d\u305f\u3044\u3002\n", "\u306a\u304a\u3001\u3044\u304f\u3064\u304b\u5b9f\u6570\u5024\u3092\u89e3\u7b54\u3059\u308b\u8ab2\u984c\u304c\u3042\u308b\u304c\u3001**\u8aa4\u5dee\u306f0.01\u307e\u3067\u8a31\u5bb9\u3059\u308b**\u306e\u3067\u3001\u9069\u5b9c\u6841\u6570\u3092\u524a\u6e1b\u3057\u3066\u89e3\u7b54\u305b\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "GDNdG4JBn32S"}, "source": ["<!-- ENG -->\n", "In previous classes, we have mainly dealt with classification problems. But in the exercise, we will try regression problems to understand that learned methods can be applied to regression problems as well as classification problems.\n", "\n", "When real numbers are required as the answer, **errors are allowed up to 0.01**. Reduce the number of digits as appropriate."]}, {"cell_type": "markdown", "metadata": {"id": "3LnbP4nQ7F4Z"}, "source": ["------------"]}, {"cell_type": "markdown", "metadata": {"id": "Ov3Lps6z5grx"}, "source": ["<!-- JPN -->\n", "## 1 | \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u69cb\u7bc9\u3001\u30c7\u30fc\u30bf\u30af\u30ec\u30f3\u30b8\u30f3\u30b0"]}, {"cell_type": "markdown", "metadata": {"id": "T3XyNr7_prrN"}, "source": ["<!-- ENG -->\n", "## 1 | Data set construction & data cleansing"]}, {"cell_type": "markdown", "metadata": {"id": "nMzs-1tDw4ep"}, "source": ["<!-- JPN -->\n", "\u3053\u306e\u8ab2\u984c\u3067\u306f\u3001\"Auto MPG Data Set\" \u3092\u5143\u3068\u3057\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 `mpg_dataset.csv` \u3092\u7528\u3044\u308b\u3002\u3053\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u306f1970\u5e74\u304b\u30891982\u5e74\u307e\u3067\u306b\u88fd\u9020\u3055\u308c\u305f\u8eca\u306b\u3064\u3044\u3066\u3001\u8907\u6570\u306e\u8eca\u306e\u6027\u80fd\u60c5\u5831\u3068\u3001\u305d\u306e\u8eca\u306e\u71c3\u8cbb\u304c\u307e\u3068\u3081\u3089\u308c\u3066\u3044\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "6lNgskdLp7k0"}, "source": ["<!-- ENG -->\n", "For this assignment, we use the dataset `mpg_dataset.csv`, which is based on the \"Auto MPG Data Set\". This dataset contains the performance information of several cars manufactured between 1970 and 1982, as well as the fuel consumption of those cars."]}, {"cell_type": "markdown", "metadata": {"id": "vUD4URXUxL-D"}, "source": ["<!-- JPN -->\n", "\u307e\u305a\u306f pandas \u3092\u5229\u7528\u3057\u3066\u3001\u3053\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8aad\u307f\u8fbc\u3080\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "wfEG4Ol_qBUo"}, "source": ["<!-- ENG -->\n", "First, we read this data set using pandas."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "7pNRIWMj3Yoq"}, "outputs": [], "source": ["import pandas as pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "V2berNSOw0Gf"}, "outputs": [], "source": ["# Please do not change the file path (because of auto-grading)\n", "# Use of packages dedicated to google drive is also not allowed \n", "df = pd.read_csv(\"mpg_dataset.csv\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "qesxA2Rbmar5"}, "outputs": [], "source": ["print(df.head())"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "B92U74ez6Q6o"}, "outputs": [], "source": ["print(df.columns) # Show all column names"]}, {"cell_type": "markdown", "metadata": {"id": "TAvopHRbwlOD"}, "source": ["<!-- JPN -->\n", "\n", "\u3053\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u6301\u3064\u5909\u6570\uff08\u7279\u5fb4\u91cf\uff09\u306e\u8aac\u660e\u3092\u7c21\u5358\u306b\u8a18\u8f09\u3059\u308b\u3002\n", "\n", "|  \u5909\u6570  | \u8aac\u660e  |\n", "| ---- | ---- |\n", "|  MPG  |  \u71c3\u8cbb\uff081\u30ac\u30ed\u30f3\u3067\u4f55\u30de\u30a4\u30eb\u8d70\u308c\u308b\u304b\uff09  |\n", "|  Cylinders  | \u6c17\u7b52\u6570 |\n", "| Displacement | \u6392\u6c17\u91cf |\n", "| Horsepower | \u99ac\u529b |\n", "|Acceleration | \u52a0\u901f\u5ea6 |\n", "|Model Year| \u30e2\u30c7\u30eb\u5e74\u5f0f\uff08\u88fd\u9020\u5e74\uff09|\n", "|Origin| \u88fd\u9020\u4f01\u696d\u306e\u6240\u5728\u5730\uff081 \u30a2\u30e1\u30ea\u30ab\u30012 \u30e8\u30fc\u30ed\u30c3\u30d1\u30013 \u65e5\u672c\uff09|\n", "|Weight Category | \u8eca\u4f53\u306e\u91cd\u91cf \uff081 2000\u30dd\u30f3\u30c9\u672a\u6e80\u30012 2000-3000\u30dd\u30f3\u30c9\u30013 3000-4000\u30dd\u30f3\u30c9\u30014 4000\u30dd\u30f3\u30c9\u4ee5\u4e0a\uff09|\n"]}, {"cell_type": "markdown", "metadata": {"id": "SWKYdPTG6Jv0"}, "source": ["<!-- ENG -->\n", "The following is a brief description of the variables (features) that this data set has.\n", "\n", "| Variable | Description\n", "| ---- | ---- |\n", "| MPG | Fuel consumption (how many miles you can drive in one gallon) |\n", "| Cylinders | Number of cylinders |\n", "| Displacement | Engine displacement |\n", "| Horsepower | Engine power |\n", "|Acceleration | Acceleration performance |\n", "|Model Year| Model Year (year of manufacture) |\n", "|Origin| Manufacturer's Location (1 USA, 2 Europe, 3 Japan) |\n", "|Weight Category | Vehicle Weight (1 Less than 2000 lbs, 2 2000-3000 lbs, 3 3000-4000 lbs, 4 More than 4000 lbs) |\n"]}, {"cell_type": "markdown", "metadata": {"id": "1KsZGc337O-H"}, "source": ["----------------"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "zhDLKsLF7EMf"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 1.1"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "JF6wT_meq-iI"}, "source": ["<!-- ENG -->\n", "### Exercise 1.1"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "63z6FaKMxrls"}, "source": ["<!-- JPN -->\n", "\u3053\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u6301\u3064\u5909\u6570\uff08\u7279\u5fb4\u91cf\uff09\u306e\u3046\u3061\u3001\u6b20\u640d\u5024\u3092\u542b\u3080\u5217\u540d\u3092\u5168\u3066\u307e\u3068\u3081\u305f\u914d\u5217\u3092 `variables_with_missing_values` \u306b\u4ee3\u5165\u305b\u3088\u3002\n"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "jDoKiyqyq7oD"}, "source": ["<!-- ENG -->\n", "Which of the variables (features) in this data set contain missing values? Create a list of the name of variables and assign it to `variables_with_missing_values`. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ["# CODE CELL FOR YOUR ANSWER\n", "import pandas as pd\n", "\n", "# Please do not change the file path (because of auto-grading)\n", "# Use of packages dedicated to google drive is also not allowed \n", "df = pd.read_csv(\"mpg_dataset.csv\")\n", "\n", "variables_with_missing_values = ...\n"]}, {"cell_type": "markdown", "metadata": {"id": "fIVp6A3b7ArI"}, "source": ["----------------------"]}, {"cell_type": "markdown", "metadata": {"id": "ssHsRRsdDepX"}, "source": ["<!-- JPN -->\n", "\u3053\u3053\u3067\u306f\u3001\u6b20\u640d\u5024\u3092\u542b\u3080\u8eca\u306e\u30c7\u30fc\u30bf\u306f\uff08\u5168\u4f53\u306e2,3%\u7a0b\u5ea6\u306a\u306e\u3067\uff09\u524a\u9664\u3057\u3066\u3057\u307e\u304a\u3046\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "VPOz0e2ZrEmJ"}, "source": ["<!-- ENG -->\n", "Here, let's delete the data of cars that contain missing values (since they are only 2 or 3% of the total)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "1E2Ivjl0Dmg3"}, "outputs": [], "source": ["df = df.dropna()"]}, {"cell_type": "markdown", "metadata": {"id": "XIUQsyLqDavW"}, "source": ["<!-- JPN -->\n", "\u4eca\u56de\u7528\u3044\u308b\u7279\u5fb4\u91cf\u306f\u3001\u4e00\u90e8**\u9023\u7d9a\u5024\u3068\u3057\u3066\u7528\u3044\u308b\u306e\u304c\u4e0d\u9069**\u306a\u3082\u306e\u304c\u5b58\u5728\u3059\u308b\u3002\u3053\u306e\u3088\u3046\u306a\u7279\u5fb4\u91cf\u306b\u5bfe\u3057\u3066\u306f\u3001**one-hot encoding** \u3092\u884c\u3046\u3053\u3068\u304c\u6700\u3082\u5358\u7d14\u306a\u5bfe\u7b56\u3068\u306a\u308b\u3002\u3053\u306e\u64cd\u4f5c\u306f\u3001\u3042\u308b\u7279\u5fb4\u91cf\u3092\u8907\u6570\u306e0,1\u3067\u8868\u73fe\u3059\u308b\u3082\u306e\u3067\u3042\u308b\u3002\n", "\n", "\u3000\u4f8b\u3048\u3070\u3001\u3042\u308b\u7279\u5fb4\u91cf\u306f \"h\", \"l\", \"s\" \u306e\u3044\u305a\u308c\u304b1\u6587\u5b57\u3067\u8868\u73fe\u3055\u308c\u3066\u3044\u305f\u3068\u3059\u308b\u3002\u6587\u5b57\u3092\u305d\u306e\u307e\u307e\u6a5f\u68b0\u5b66\u7fd2\u306b\u7528\u3044\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\u305f\u3081\u30011\u3064\u306e\u7279\u5fb4\u91cf\u30923\u3064\u306e\u6570\u5024\u3067\u8868\u73fe\u3059\u308b\u3053\u3068\u3067\u5b66\u7fd2\u53ef\u80fd\u306a\u60c5\u5831\u306b\u5909\u63db\u3059\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "vy6oO4o7seVQ"}, "source": ["<!-- ENG -->\n", "Some of the features used in this assignment are **not suitable for use as continuous values**. For such features, the simplest solution is to perform **one-hot encoding**. In this operation, a feature is represented by multiple 0s and 1s.\n", "\n", "\u3000For example, suppose a feature is represented by one of the letters \"h\", \"l\", or \"s\". Since the letters cannot be used directly for machine learning, the feature is converted to learnable information by expressing it as three numbers."]}, {"cell_type": "markdown", "metadata": {"id": "mwglAA258vA-"}, "source": ["$$\n", "  h \\rightarrow [1,0,0] \\\\\n", "  l \\rightarrow [0,1,0] \\\\\n", "  s \\rightarrow [0,0,1]\n", "$$\n"]}, {"cell_type": "markdown", "metadata": {"id": "CZA5BQbU8Vbc"}, "source": ["<!-- JPN -->\n", "\u3053\u306e\u3088\u3046\u306a\u6587\u5b57\u5217\u30920,1\u5217\u306b\u5909\u63db\u3059\u308b one-hot encoding \u306f\u3001pandas\u3067\u306f `pd.get_dummies()` \u3067\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "udl4im5ns1LO"}, "source": ["<!-- ENG -->\n", "One-hot encoding, converting a string into 0,1 columns, can be done with `pd.get_dummies()` in pandas."]}, {"cell_type": "markdown", "metadata": {"id": "94BK3rackXpc"}, "source": ["<!-- JPN -->\n", "\u3000\u3053\u3053\u3067\u306f\u3001\u4e0e\u3048\u3089\u308c\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u7279\u5fb4\u91cf\u306e\u3046\u3061\u3001\"Origin\" \u3068 \"Weight Category\" \u306b\u3064\u3044\u3066 one-hot encoding \u3092\u884c\u3046\u3053\u3068\u306b\u3059\u308b\u3002\u305f\u3060\u3057\u3001 \"Origin\" \u3082 \"Weight Category\" \u3082\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u4e2d\u3067\u306f\u6570\u5024\u3067\u8868\u73fe\u3055\u308c\u3066\u3044\u308b\u304c\u3001 `pd.get_dummies()` \u306f\u5143\u3005\u6570\u5024\u3067\u3042\u308b\u7279\u5fb4\u91cf\u3092 one-hot encoding \u306e\u5bfe\u8c61\u306b\u3057\u306a\u3044\u3002\u6570\u5024\u3092\u4e00\u65e6\u6587\u5b57\u5217\u306b\u5909\u63db\u3057\u3001\u305d\u306e\u5f8c\u306b `pd.get_dummies()` \u95a2\u6570\u3092\u7528\u3044\u308b\u3053\u3068\u3067 one-hot encoding \u3092\u5b9f\u73fe\u3059\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "m48PUf0VtXbk"}, "source": ["<!-- ENG -->\n", "\u3000Here, we perform one-hot encoding for the features \"Origin\" and \"Weight Category\" in the given dataset. While \"Origin\" and \"Weight Category\" are both represented as numbers in the dataset, `pd.get_dummies()` does not perform one-hot encoding on features that are originally numbers. So, converting numeric values to strings and then using the `pd.get_dummies()` function will realize one-hot encoding."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "09AmFY6JE1Cr"}, "outputs": [], "source": ["# one-hot encoding by get_dummies() without casting numerical values to string\n", "df = pd.get_dummies(df)\n", "# it will not affect numerical columns\n", "print(df.columns)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "2rRf2d0MUG9l"}, "outputs": [], "source": ["# cast from numerical value to string\n", "df[\"Origin\"] = df[\"Origin\"].astype(str)\n", "df[\"Weight Category\"] = df[\"Weight Category\"].astype(str)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "jAKwef-t2d11"}, "outputs": [], "source": ["df = pd.get_dummies(df)\n", "print(df.columns)"]}, {"cell_type": "markdown", "metadata": {"id": "Cqlou-DW37f0"}, "source": ["<!-- JPN -->\n", "\u3000\u3053\u308c\u306b\u3088\u308a\u3001\u4f8b\u3048\u3070 \"Origin\" \u306f \"Origin_1\", \"Origin_2\", \"Origin_3\" \u306e3\u3064\u306e\u7279\u5fb4\u91cf\u306b\u5206\u5272\u3055\u308c\u305f\u3053\u3068\u304c\u308f\u304b\u308b\u3002\u305d\u306e\u3046\u3061\u5fc5\u305a1\u3064\u304c `1` \u306b\u306a\u3063\u3066\u304a\u308a\u3001\u305d\u306e\u4ed6\u306f `0` \u3068\u306a\u3063\u3066\u3044\u308b\u3053\u3068\u306f\u5404\u81ea\u78ba\u8a8d\u3057\u3066\u307b\u3057\u3044\uff08\u8ab2\u984c\u3067\u306f\u306a\u3044\uff09\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "OTDzxV2htlen"}, "source": ["<!-- ENG -->\n", "\u3000We can now see that, for example, \"Origin\" has been split into three features: \"Origin_1\", \"Origin_2\", and \"Origin_3\". Please check that one of them is always `1` and the others are `0` (not an assignment)."]}, {"cell_type": "markdown", "metadata": {"id": "6uJK4nXdRj7V"}, "source": ["<!-- JPN -->\n", "\u3000\u7d9a\u3044\u3066\u3001\u3053\u306e\u30c7\u30fc\u30bf\u3092\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5206\u5272\u3057\u3088\u3046\u3002\u3053\u3053\u3067\u306f\u3001\u6388\u696d\u3067\u53d6\u308a\u6271\u3063\u305f `train_test_split()` \u3092\u7528\u3044\u308b\u4ee3\u308f\u308a\u306b\u3001 **\"Model Year\" \u304c80\u672a\u6e80\uff081970\u5e74\u4ee3\uff09\u306e\u3082\u306e\u3092\u8a13\u7df4\u30c7\u30fc\u30bf\u3001\"Model Year\" \u304c80\u4ee5\u4e0a\uff081980\u5e74\u4ee3\uff09\u306e\u3082\u306e\u3092\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf**\u3068\u3059\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "GkSFeE6ft1Ia"}, "source": ["<!-- ENG -->\n", "\u3000Next, let's split this dataset into training data and test data. Here, instead of using `train_test_split()` as we did in the lecture, let's use **the data whose \"Model Year\" is less than 80 (1970s) as the training data, and the data whose \"Model Year\" is equal to or more than 80 (1980s) as the test data**."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "i2n6DvmpSCoW"}, "outputs": [], "source": ["train_df = df[df[\"Model Year\"] <  80]\n", "test_df  = df[df[\"Model Year\"] >= 80]"]}, {"cell_type": "markdown", "metadata": {"id": "71cQJcask7e-"}, "source": ["<!-- JPN -->\n", "\u3053\u308c\u3067\u3001\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u6e96\u5099\u304c\u5b8c\u4e86\u3057\u305f\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "i7Ag-wO9t6za"}, "source": ["<!-- ENG -->\n", "Now, the training and test data are ready."]}, {"cell_type": "markdown", "metadata": {"id": "T0OBZRM4_Far"}, "source": ["<!-- JPN -->\n", "\u3000\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u6e96\u5099\u306e\u4ed5\u4e0a\u3052\u3068\u3057\u3066\u3001\u305d\u308c\u305e\u308c\u306e\u30c7\u30fc\u30bf\u3092\u8aac\u660e\u5909\u6570 `X` \u3068\u76ee\u7684\u5909\u6570 `y` \u306b\u5206\u5272\u3057\u3088\u3046\u3002\uff08\u4e8b\u5f8c\u306e\u51e6\u7406\u3092\u7c21\u5358\u306b\u3059\u308b\u305f\u3081\u306b\u3001pandas DataFrame\u306e\u307e\u307e `X` \u3092\u6e96\u5099\u3059\u308b\u3002\u3053\u308c\u3067\u3082\u3053\u306e\u5f8c\u306escikit-learn\u3092\u305d\u306e\u307e\u307e\u4f7f\u3048\u308b\u306e\u3067\u899a\u3048\u3066\u304a\u3053\u3046\uff09"]}, {"cell_type": "markdown", "metadata": {"id": "ts1houvzueQE"}, "source": ["<!-- ENG -->\n", "\u3000Finally, let's split each dataset into explanatory variables `X` and objective variables `y`. (To simplify the following process, let's prepare `X` as a pandas DataFrame (Keep in mind that this is still possible to use directly with scikit-learn)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "Qck7yotu_scH"}, "outputs": [], "source": ["# MPG is the objective value\n", "\n", "train_X = train_df.drop(\"MPG\", axis=1)\n", "test_X  = test_df.drop(\"MPG\", axis=1)\n", "\n", "train_y = train_df[\"MPG\"].to_numpy()\n", "test_y  = test_df[\"MPG\"].to_numpy()"]}, {"cell_type": "markdown", "metadata": {"id": "n3dBv59o-iOT"}, "source": ["------"]}, {"cell_type": "markdown", "metadata": {"id": "vTVNOvnsN1Yl"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 1.2\n", "\n", "\u3000\u3053\u3053\u3067\u306f\u3001\"Origin\" \u3068 \"Weight Category\" \u306b\u3064\u3044\u3066 one-hot encoding \u3092\u5b9f\u65bd\u3057\u305f\u3002\u3053\u306e\u3046\u3061\u3001\"Origin\" \u306b\u3064\u3044\u3066\u3001\u4f55\u6545 one-hot encoding \u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u304b\u3001\u9078\u629e\u80a2\u304b\u3089\u6700\u3082\u9069\u5207\u306a\u3082\u306e\u3092\u9078\u629e\u305b\u3088\u3002\n", "\n", "1. \u76ee\u7684\u5909\u6570\u3067\u3042\u308b \"MPG\" \u3068 \"Origin\" \u3068\u306e\u9593\u306b\u5341\u5206\u306a\u76f8\u95a2\u304c\u89b3\u6e2c\u3067\u304d\u306a\u304b\u3063\u305f\u304b\u3089\n", "2. \u88fd\u9020\u56fd\u3092\u8b58\u5225\u3059\u308b\u305f\u3081\u306e\u8a18\u53f7\u3067\u3042\u308a\u3001\u305d\u306e\u6570\u5024\u306e\u5927\u5c0f\u95a2\u4fc2\u306b\u610f\u5473\u304c\u306a\u3044\u304b\u3089\n", "3. \"Origin\" \u306e\u5024\u306b\u5927\u304d\u306a\u504f\u308a\u304c\u3042\u308a\u3001 one-hot encoding \u3092\u3059\u308b\u3053\u3068\u3067\u305d\u306e\u504f\u308a\u3092\u4f4e\u6e1b\u3067\u304d\u308b\u304b\u3089\n"]}, {"cell_type": "markdown", "metadata": {"id": "6pWFdz6Xu4wV"}, "source": ["<!-- ENG -->\n", "### Exercise 1.2\n", "\n", "\u3000In this section, one-hot encoding was performed for \"Origin\" and \"Weight Category\". For \"Origin\", choose the most appropriate reason why one-hot encoding must be performed. \n", "\n", "1. Because we could not observe a sufficient correlation between the objective variable \"MPG\" and the variable \"Origin\"\n", "2. Because it is a symbol used to identify the country of manufacture, and the magnitude of the values is meaningless\n", "3. There is a large bias in the value of \"Origin\" and one-hot encoding can reduce the bias.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "PTvB4p-5-je1"}, "source": ["------"]}, {"cell_type": "markdown", "metadata": {"id": "ZeMLVp9oPB4y"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 1.3\uff08\u767a\u5c55\uff09\n", "\n", "\u3000\u7dda\u5f62\u56de\u5e30\u3084\u591a\u9805\u5f0f\u56de\u5e30\u3001\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3001\u4e3b\u6210\u5206\u5206\u6790\u306a\u3069\u3092\u7528\u3044\u308b\u969b\u306b\u306f \"Weight Category\" \u306f one-hot encoding \u3059\u308b\u3053\u3068\u304c\u9069\u5207\u3067\u3042\u308b\u3002\u4e00\u65b9\u3067**\u6c7a\u5b9a\u6728\u306b\u57fa\u3065\u304f\u65b9\u6cd5\uff08\u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u306a\u3069\u3092\u542b\u3080\uff09\u306e\u5834\u5408\u306f \"Weight Category\" \u306f\u5fc5\u305a\u3057\u3082 one-hot encoding \u3059\u308b\u5fc5\u8981\u304c\u306a\u3044**\u3002\u7406\u7531\u3092\u7b54\u3048\u3088\u3002\n"]}, {"cell_type": "markdown", "metadata": {"id": "lW7RkBWevEYo"}, "source": ["<!-- ENG -->\n", "### Exercise 1.3 (Advanced)\n", "\n", "\u3000When using linear regression, polynomial regression, neural networks, principal component analysis, etc., it is appropriate to use one-hot encoding for the \"Weight Category\". On the other hand, **for methods based on decision trees (including random forests, etc.), \"Weight Category\" does not necessarily need to be one-hot encoded**. Answer why.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "vvlwO6fA-1X4"}, "source": ["----------------"]}, {"cell_type": "markdown", "metadata": {"id": "gaNiBoxURqkh"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 1.4\n", "\n", "\u3000\u88fd\u9020\u5e74\u306a\u3069\u306e\u6642\u7cfb\u5217\u306b\u57fa\u3065\u3044\u3066\u30c7\u30fc\u30bf\u3092\u5206\u5272\u3059\u308b\u3053\u3068\u306f\u3001`train_test_split()` \u3092\u7528\u3044\u308b\u3088\u308a\u3082\u4e00\u822c\u7684\u306b\u306f\u597d\u307e\u3057\u3044\u3002\u7406\u7531\u3068\u3057\u3066\u6700\u3082\u9069\u5207\u3082\u306e\u3092\u9078\u629e\u80a2\u304b\u3089\u9078\u629e\u305b\u3088\u3002\n", "\n", "1. `train_test_split()` \u306f\u30e9\u30f3\u30c0\u30e0\u6027\u304c\u3042\u308b\u305f\u3081\u306b\u6bce\u56de\u7d50\u679c\u304c\u7570\u306a\u308b\u304c\u3001\u6642\u7cfb\u5217\u306b\u57fa\u3065\u304f\u30c7\u30fc\u30bf\u5206\u5272\u306f\u5e38\u306b\u540c\u3058\u5206\u5272\u7d50\u679c\u3068\u306a\u308b\u305f\u3081\n", "2. \u6642\u7cfb\u5217\u306b\u57fa\u3065\u304f\u30c7\u30fc\u30bf\u5206\u5272\u3092\u884c\u3046\u3053\u3068\u3067\u3001\u4e88\u6e2c\u7cbe\u5ea6\u3092\u4e0b\u3052\u3001\u3088\u308a\u53b3\u5bc6\u306b\u624b\u6cd5\u3092\u6bd4\u8f03\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308b\u305f\u3081\n", "3. \u904e\u53bb\u306e\u30c7\u30fc\u30bf\u304b\u3089\u672a\u6765\u3092\u4e88\u6e2c\u3059\u308b\u3068\u3044\u3046\u95a2\u4fc2\u304c\u73fe\u5b9f\u306e\u5fdc\u7528\u306b\u5373\u3057\u3066\u3044\u308b\u305f\u3081\n"]}, {"cell_type": "markdown", "metadata": {"id": "w418PoTJv0B7"}, "source": ["<!-- ENG -->\n", "### Exercise 1.4\n", "\n", "\u3000Splitting data based on a time series, such as year of manufacture, is generally preferable to using `train_test_split()`. Choose the most appropriate reason from the choices. \n", "\n", "1. Because the result of `train_test_split()` varies each time due to randomness, but the result of splitting data based on time series is always the same.\n", "2. Because time-series based data splitting reduces the prediction accuracy and allows us to compare methods more rigorously.\n", "3. Because the relationship of predicting the future from the past data is consistent with real-world applications.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "UT7lMmxS_EMk"}, "source": ["-------"]}, {"cell_type": "markdown", "metadata": {"id": "YI94oZABA4F6"}, "source": ["<!-- JPN -->\n", "## 2 | \u6559\u5e2b\u306a\u3057\u5b66\u7fd2\uff1a\u4e3b\u6210\u5206\u5206\u6790\u306b\u3088\u308b\u53ef\u8996\u5316"]}, {"cell_type": "markdown", "metadata": {"id": "loImNk5fpX53"}, "source": ["<!-- ENG -->\n", "## 2 | Unsupervised learning: visualization by principal component analysis"]}, {"cell_type": "markdown", "metadata": {"id": "Eiap8aUUBPPg"}, "source": ["<!-- JPN -->\n", "\u3000\u6e96\u5099\u3055\u308c\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f10\u500b\u4ee5\u4e0a\u306e\u7279\u5fb4\u91cf\u304b\u3089\u69cb\u6210\u3055\u308c\u3066\u3044\u308b\u305f\u3081\u3001\u8996\u899a\u7684\u306b\u308f\u304b\u308a\u3084\u3059\u3044\u6563\u5e03\u56f3\u3092\u4f5c\u308b\u3053\u3068\u306f\u96e3\u3057\u3044\u3002\u305d\u306e\u4ee3\u308f\u308a\u306b\u3001**\u4e3b\u6210\u5206\u5206\u6790\u306b\u3088\u308b\u6b21\u5143\u524a\u6e1b**\u3092\u901a\u3057\u3066\u3069\u306e\u3088\u3046\u306a\u30c7\u30fc\u30bf\u70b9\u306e\u5206\u5e03\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u304b\u3092\u78ba\u8a8d\u3059\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "1XYldXKzpjyb"}, "source": ["<!-- ENG -->\n", "  Since the prepared data set consists of more than 10 features, it is difficult to create a scatter plot that is easy to understand visually. Instead, we will check how the data points are distributed through **dimensionality reduction by principal component analysis (PCA)**."]}, {"cell_type": "markdown", "metadata": {"id": "_u_ggAPyB1yG"}, "source": ["<!-- JPN -->\n", "\u3000\u4eca\u56de\u306e\u30c7\u30fc\u30bf\u3067\u306f\u5024\u306e\u7bc4\u56f2\u304c\u5404\u7279\u5fb4\u91cf\u3067\u5927\u304d\u304f\u7570\u306a\u308a\u3001\u4e3b\u6210\u5206\u5206\u6790\u306e\u5bc4\u4e0e\u7387\u306e\u7b97\u51fa\u306b\u60aa\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u305f\u3081\u3001\u3053\u3053\u3067\u306f\u5404\u7279\u5fb4\u91cf\u306e\u6a19\u6e96\u5316\u3092\u884c\u3063\u305f\u4e0a\u3067\u4e3b\u6210\u5206\u5206\u6790\u3092\u884c\u3046\u3053\u3068\u306b\u3059\u308b\u3002\u306a\u304a\u3001\u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u3067\u51fa\u3066\u304f\u308b `fit_transform()` \u3068\u306f\u3001\u540c\u4e00\u306e\u5165\u529b\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066 `fit()` \u3092\u884c\u3063\u3066\u304b\u3089 `transform()` \u3092\u884c\u3046\u30e1\u30bd\u30c3\u30c9\uff08\u95a2\u6570\uff09\u3067\u3042\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "BUT7rK1ZY_KC"}, "source": ["<!-- ENG -->\n", "In this data, the range of values differs greatly for each feature, which adversely affects the calculation of the explained variance ratio of PCA. Therefore, we will standardize each feature before performing principal component analysis. Note that `fit_transform()` in the following code is the method (function) that performs `fit()` and then `transform()` for the same input data."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "z6v0AJCimmKR"}, "outputs": [], "source": ["# standardization of features\n", "from sklearn.preprocessing import StandardScaler\n", "\n", "ss = StandardScaler()\n", "train_std_X = ss.fit_transform(train_X)\n", "test_std_X  = ss.transform(test_X)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "Gto9RLH6nOv4"}, "outputs": [], "source": ["# principal component analysis\n", "from sklearn.decomposition import PCA\n", "\n", "pca = PCA(n_components=2)\n", "train_std_pca_X = pca.fit_transform(train_std_X)\n", "test_std_pca_X  = pca.transform(test_std_X)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "Iw1xXKNgnoTR"}, "outputs": [], "source": ["# scatter plot with two principal components\n", "import matplotlib.pyplot as plt\n", "plt.scatter(train_std_pca_X[:,0], train_std_pca_X[:,1], label=\"training dataset\")\n", "plt.scatter(test_std_pca_X[:,0],  test_std_pca_X[:,1],  label=\"test dataset\")\n", "plt.xlabel(\"PC1\")\n", "plt.ylabel(\"PC2\")\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"id": "3IyPC7HYb5oE"}, "source": ["<!-- JPN -->\n", "\u3000\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u540c\u3058\u7a7a\u9593\u306b\u63cf\u753b\u3059\u308b\u3068\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u5404\u70b9\u306f\u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u8fd1\u304f\u306b\u5b58\u5728\u3057\u3066\u3044\u308b\u3088\u3046\u3060\u3002\u3053\u306e\u5834\u5408\u306b\u306f\u5b66\u7fd2\u3057\u305f\u30e2\u30c7\u30eb\u304c\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u9069\u5207\u306b\u4e88\u6e2c\u3057\u3066\u304f\u308c\u308b\u53ef\u80fd\u6027\u304c\u9ad8\u3044\uff08\u3088\u308a\u8a73\u7d30\u306a\u8b70\u8ad6\u306f\u300c\u9069\u7528\u9818\u57df applicability domain\u300d\u306a\u3069\u3067\u691c\u7d22\u3059\u308b\u3068\u826f\u3044\uff09\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "symo5P11bDPv"}, "source": ["<!-- ENG -->\n", "When the training and test data are drawn in the same space, each point of the test data seems to exist close to the training data. In this case, the trained model is more likely to predict the test data appropriately (for more detailed discussion, search for \"applicability domain\" etc.)"]}, {"cell_type": "markdown", "metadata": {"id": "rm6hxohPqHMe"}, "source": ["<!-- JPN -->\n", "\u3000\u3057\u304b\u3057\u306a\u304c\u3089\u3001**\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u304c\u4e3b\u6210\u5206\u5206\u6790\u306e\u5c04\u5f71\u7a7a\u9593\u4e0a\u3067\u8fd1\u508d\u306b\u3042\u308b\u3060\u3051\u3067\u306f\u4e88\u6e2c\u304c\u3046\u307e\u304f\u884c\u304f\u6761\u4ef6\u3068\u3057\u3066\u306f\u4e0d\u5341\u5206**\u3067\u3042\u308b\u3002\u306a\u305c\u306a\u3089\u3001\u3053\u308c\u3089\u306e**\u4e3b\u6210\u5206\u304c\u76ee\u7684\u5909\u6570\u306e\u4e88\u6e2c\u306b\u6709\u7528\u3068\u306f\u9650\u3089\u306a\u3044**\u304b\u3089\u3060\u3002\u305d\u3053\u3067\u3001\u3053\u3053\u3067\u306f\u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u5404\u70b9\u304c\u3069\u306e\u3088\u3046\u306a\u76ee\u7684\u5909\u6570 MPG \u3067\u3042\u308b\u304b\u3092\u5408\u308f\u305b\u3066\u63cf\u753b\u3057\u3001\u4e88\u6e2c\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306b\u6a5f\u80fd\u3057\u305d\u3046\u304b\u3092\u8a55\u4fa1\u3057\u3066\u307f\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "T82juMkMdIqT"}, "source": ["<!-- ENG -->\n", "\u3000However, the mere fact that **training and test data are close together in the projection space of principal component analysis** is not a sufficient condition for successful prediction. This is because these **principal components are not always useful for predicting the target variable**. In this section, we will try to evaluate whether the prediction model works well by drawing the MPG (the target variable) on each point in the training data."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "Grsr_GlIrT4F"}, "outputs": [], "source": ["plt.scatter(train_std_pca_X[:,0], train_std_pca_X[:,1], c=train_y, cmap=\"jet\")\n", "plt.colorbar()\n", "plt.xlabel(\"PC1\")\n", "plt.ylabel(\"PC2\")\n", "plt.title(\"MPG (training dataset)\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"id": "RC0cZ_-ZrBFW"}, "source": ["<!-- JPN -->\n", "\u3000\u3053\u306e\u56f3\u3092\u898b\u308b\u9650\u308a\u3001\u5927\u307e\u304b\u306b\u300cPC1\u306e\u5024\u304c\u9ad8\u3044\u307b\u3069\u71c3\u8cbb\u304c\u60aa\u304f\uff08MPG\u306e\u5024\u304c\u4f4e\u304f\uff09\u300d\u3001\u300cPC2\u306e\u5024\u304c\u9ad8\u3044\u307b\u3069\u71c3\u8cbb\u304c\u826f\u3044\uff08MPG\u306e\u5024\u304c\u9ad8\u3044\uff09\u300d\u3068\u3044\u3046\u50be\u5411\u304c\u898b\u3089\u308c\u3001**\u76ee\u7684\u5909\u6570\u306e\u4e88\u6e2c\u304c\u3053\u306e2\u3064\u306e\u4e3b\u6210\u5206\u304b\u3089\u884c\u3048\u308b\u3053\u3068\u304c\u793a\u5506**\u3055\u308c\u305f\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "LtJgNWqydlzw"}, "source": ["<!-- ENG -->\n", "\u3000This figure shows a general trend that the higher the value of PC1, the worse the fuel economy (lower value of MPG), and the higher the value of PC2, the better the fuel economy (higher value of MPG), suggesting that **the objective variable can be predicted from these two principal components**."]}, {"cell_type": "markdown", "metadata": {"id": "J09fMfZLsy0v"}, "source": ["<!-- JPN -->\n", "\u3000\u4ee5\u4e0a\u306e\u8b70\u8ad6\u304b\u3089\u3001\u4ee5\u4e0b2\u70b9\u306e\u4e8b\u5b9f\u304c\u308f\u304b\u3063\u305f\u3002\n", "\n", "- \u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306f\u3001\u7b2c1\u4e3b\u6210\u5206\u304a\u3088\u3073\u7b2c2\u4e3b\u6210\u5206\u304b\u3089\u306a\u308b**\u5c04\u5f71\u7a7a\u9593\u4e2d\u3067\u96a3\u63a5**\u3057\u3042\u3063\u3066\u3044\u308b\u3002\n", "- \u7b2c1\u4e3b\u6210\u5206\u304a\u3088\u3073\u7b2c2\u4e3b\u6210\u5206\u306fMPG\u306e\u63a8\u5b9a\u306b\u6709\u7528\u3067\u3042\u308b\u3002\u3059\u306a\u308f\u3061\u3001**\u7b2c1\u4e3b\u6210\u5206\u304a\u3088\u3073\u7b2c2\u4e3b\u6210\u5206\u304c\u4f3c\u901a\u3063\u305f\u30c7\u30fc\u30bf\u306f\u4f3c\u901a\u3063\u305fMPG\u306e\u5024\u3092\u6709\u3059\u308b\u3068\u63a8\u6e2c**\u3055\u308c\u308b\u3002\n", "\n", "\u3053\u308c\u30892\u3064\u306e\u4e8b\u5b9f\u304b\u3089\u3001**\u8a13\u7df4\u30c7\u30fc\u30bf\u304b\u3089\u5b66\u7fd2\u3055\u308c\u305f\u30e2\u30c7\u30eb\u306f\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3082\u9069\u5207\u306b\u4e88\u6e2c\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd**\u3067\u3042\u308b\u3068\u63a8\u5b9a\u3055\u308c\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "f5-ooM3_sW6t"}, "source": ["<!-- ENG -->\n", "From the above discussion, the following two facts were found.\n", "\n", "* The training data and the test data are adjacent to each other in the projective space consisting of the first and second principal components.\n", "* The first and second principal components are useful for MPG estimation. That is, data with similar first and second principal components are estimated to have similar MPG values.\n", "\n", "From these two facts, it can be inferred that the model trained from the training data can also predict the test data adequately."]}, {"cell_type": "markdown", "metadata": {"id": "gKta-rbqniQ0"}, "source": ["------"]}, {"cell_type": "markdown", "metadata": {"id": "l5PTjtu3bdl6"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 2.1\n", "\n", "\u4ee5\u4e0b\u306e\u7a7a\u6b04\u306b\u9069\u5207\u306a\u6570\u5024\u3092\u8a18\u5165\u305b\u3088\u3002\n", "\n", "```\n", "\u6a19\u6e96\u5316 standardization \u3068\u306f\u3001\u5404\u7279\u5fb4\u91cf\u306b\u3064\u3044\u3066\u3001\u5e73\u5747 [ ]\u3001\u5206\u6563 [ ] \u306b\u306a\u308b\u3088\u3046\u306b\u5024\u3092\u5909\u63db\u3059\u308b\u64cd\u4f5c\u306e\u3053\u3068\u3092\u6307\u3059\u3002\n", "```"]}, {"cell_type": "markdown", "metadata": {"id": "7b6Yuw3ystY6"}, "source": ["<!-- ENG -->\n", "### Exercise 2.1\n", "\n", "Fill in the blanks below with the appropriate numbers.\n", "\n", "```\n", "Standardization refers to the operation of transforming the values for each feature so that the mean [ ] and variance [ ].\n", "```"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "4qumgTkrnj7u"}, "source": ["------"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "lyPg1erWamD3"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 2.2\n", "\n", "PCA\u3067\u7d2f\u7a4d\u5bc4\u4e0e\u7387\u304c80%\u3092\u8d8a\u3048\u308b\u6700\u5c0f\u306e\u6b21\u5143\u6570 `n_minimum_pcs` \u3092\u6c42\u3081\u3088\u3002\u305f\u3060\u3057\u3001PCA\u306f\u6a19\u6e96\u5316\u5f8c\u306e\u8aac\u660e\u5909\u6570\u306b\u5bfe\u3057\u3066\u884c\u3048\u3002"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "RwplDx5_tK9p"}, "source": ["<!-- ENG -->\n", "### Exercise 2.2\n", "\n", "Find the minimum number of dimensions `n_minimum_pcs` for which the cumulative contribution exceeds 80% in PCA? Note that PCA should be performed for the standardized explanatory variables."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ["# CODE CELL FOR YOUR ANSWER\n", "\n", "from sklearn.decomposition import PCA\n", "import numpy as np\n", "\n", "pca = PCA(n_components=...)\n", "...\n", "n_minimum_pcs = ...\n"]}, {"cell_type": "markdown", "metadata": {"id": "gFV9KTfXnkrk"}, "source": ["------"]}, {"cell_type": "markdown", "metadata": {"id": "8Dirg2h0uRXA"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 2.3\uff08\u767a\u5c55\uff09\n", "\n", "\u4eca\u56de\u306e\u89e3\u6790\u3067\u306f\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u8aac\u660e\u5909\u6570 `test_X` \u304c\u3042\u3089\u304b\u3058\u3081\u308f\u304b\u3063\u3066\u3044\u308b\u3053\u3068\u3092\u524d\u63d0\u3068\u3057\u3066\u3044\u305f\u304c\u3001\u73fe\u5b9f\u306e\u554f\u984c\u3067\u306f\u5fc5\u305a\u3057\u3082\u305d\u3046\u3067\u3042\u308b\u3068\u306f\u9650\u3089\u306a\u3044\u3002\u4f8b\u3048\u3070\u3001\u30bb\u30f3\u30b5\u30fc\u306e\u60c5\u5831\u304b\u3089\u6a5f\u68b0\u304c\u6b63\u5e38\u306b\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u5426\u304b\u3092\u4e88\u6e2c\u3059\u308b\u5834\u5408\u3001\u5b9f\u969b\u306b\u4e88\u6e2c\u3059\u308b\u30bf\u30a4\u30df\u30f3\u30b0\u306b\u306a\u308b\u307e\u3067\u30bb\u30f3\u30b5\u30fc\u306e\u5024 `test_X` \u3092\u5f97\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\u3002\n", "\n", "\u3000\u4e88\u6e2c\u30e2\u30c7\u30eb\u306e\u69cb\u7bc9\u6642\u306b**\u65e2\u306b\u4e88\u6e2c\u3059\u3079\u304d\u30c7\u30fc\u30bf\u306e\u8aac\u660e\u5909\u6570\u306e\u5024\u304c\u3042\u3089\u304b\u3058\u3081\u308f\u304b\u3063\u3066\u3044\u308b**\u5834\u5408\u306e\u4f8b\u3068\u3001**\u4e88\u6e2c\u30e2\u30c7\u30eb\u306e\u69cb\u7bc9\u6642\u306b\u4e88\u6e2c\u3059\u3079\u304d\u30c7\u30fc\u30bf\u306e\u8aac\u660e\u5909\u6570\u306e\u5024\u304c\u307e\u3060\u308f\u304b\u3089\u306a\u3044**\u5834\u5408\u306e\u4f8b\u3092\u305d\u308c\u305e\u308c\u7b54\u3048\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "gIVDXtXttUer"}, "source": ["<!-- ENG -->\n", "### Exercise 2.3 (Advanced)\n", "\n", "In this analysis, it was assumed that the explanatory variables of the test data `test_X` were known in advance, but this is not always the case in real problems. For example, when predicting whether or not a machine is working correctly based on sensor information, the sensor value `test_X` cannot be obtained until the actual timing of the prediction.\n", "\n", "\u3000Give an example of a case where the explanatory variables of the data to be predicted **are already known in advance** when building the prediction model, and an example of a case where the explanatory variables of the data to be predicted **are not yet known** when building the prediction model, respectively."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "93ke1EsduPkj"}, "source": ["------"]}, {"cell_type": "markdown", "metadata": {"id": "SQOShFL2v70v"}, "source": ["<!-- JPN -->\n", "## 3 | \u6559\u5e2b\u3042\u308a\u5b66\u7fd2\uff1a\u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u3068\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u63a2\u7d22"]}, {"cell_type": "markdown", "metadata": {"id": "UDKHviyOtqDQ"}, "source": ["<!-- ENG -->\n", "## 3 | Supervised Learning: Random Forest and Hyperparameter Search"]}, {"cell_type": "markdown", "metadata": {"id": "OpALekmBwBlP"}, "source": ["<!-- JPN -->\n", "\u3000\u6700\u5f8c\u306b\u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u3092\u7528\u3044\u305f\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u3092\u884c\u3044\u3001\u3069\u306e\u7a0b\u5ea6\u306e\u7cbe\u5ea6\u304c\u51fa\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002\u6388\u696d\u3067\u306f `RandomForestClassifier()` \u3092\u7528\u3044\u305f\u304c\u3001\u3053\u308c\u306f Classifier \u3064\u307e\u308a\u5206\u985e\u306e\u305f\u3081\u306e\u30e2\u30c7\u30eb\u3067\u3042\u308b\u304c\u3001\u4eca\u56de\u306f\u56de\u5e30\u554f\u984c\u3092\u53d6\u308a\u6271\u3063\u3066\u3044\u308b\u3002\u3053\u306e\u6642\u306b\u306f `RandomForestRegressor()` \u3092\u4f7f\u3046\u3002\u307e\u305a\u306f\u4e00\u56de\u4e88\u6e2c\u3092\u884c\u3063\u3066\u307f\u3088\u3046\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "QCBOuxfetu_s"}, "source": ["<!-- ENG -->\n", "\u3000Finally, we will perform supervised learning using random forest and evaluate the accuracy we can achieve. In the class, we used `RandomForestClassifier()`, which refers a model for classification, but this time we are dealing with a regression problem. In this case, we will use `RandomForestRegressor()`. First, let's make a prediction once."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "Lmg72wlvwitT"}, "outputs": [], "source": ["# construct regression model\n", "from sklearn.ensemble import RandomForestRegressor\n", "\n", "rfr = RandomForestRegressor(n_estimators=10, max_depth=None, random_state=0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "_lVuYhMTxAv_"}, "outputs": [], "source": ["rfr.fit(train_X, train_y)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "hzAsUtJ0xM6F"}, "outputs": [], "source": ["predicted = rfr.predict(test_X)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "ziYA5XnGxP-e"}, "outputs": [], "source": ["print(predicted)"]}, {"cell_type": "markdown", "metadata": {"id": "d7bOMVc-xSXT"}, "source": ["<!-- JPN -->\n", "\u3000\u4e88\u6e2c\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u305f\u3002\u5148\u307b\u3069\u76ee\u8996\u3057\u305fMPG\u306e\u6570\u5024\u304b\u3089\u306f\u5927\u304d\u304f\u5916\u308c\u3066\u306f\u3044\u306a\u3044\u3053\u3068\u304c\u308f\u304b\u308b\u3002\u5b9f\u969b\u306b\u4e88\u6e2c\u304c\u3069\u306e\u7a0b\u5ea6\u6b63\u78ba\u306a\u306e\u304b\u3001\u8a55\u4fa1\u3092\u884c\u3046\u3002\u8a55\u4fa1\u6307\u6a19\u3068\u3057\u3066\u306f\u5e73\u5747\u4e8c\u4e57\u8aa4\u5dee (mean squared error; MSE) \u3001MSE\u306e\u5e73\u65b9\u6839 (root MSE; RMSE) \u3001\u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee (mean absolute error; MAE) \u304c\u4e3b\u306b\u7528\u3044\u3089\u308c\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "aJ1jj8TVusMu"}, "source": ["<!-- ENG -->\n", "\u3000The prediction results were output. We can see that it is not far off from the MPG values we saw earlier. Here we can evaluate how accurate the prediction is. The main evaluation metrics used are mean squared error (MSE), root MSE (RMSE), and mean absolute error (MAE)."]}, {"cell_type": "markdown", "metadata": {"id": "F_oYkoCnunmy"}, "source": ["$$ \\begin{align*}\n", " \\mathrm{MSE}  &= \\frac{\\sum_{k=1}^N (y-\\hat{y})^2}{N}\\\\\n", " \\mathrm{RMSE} &= \\sqrt{\\mathstrut \\mathrm{MSE}} = \\sqrt{\\frac{\\sum_{k=1}^N (y-\\hat{y})^2}{N}} \\\\\n", " \\mathrm{MAE}  &= \\frac{\\sum_{k=1}^N |y-\\hat{y}|}{N}\n", "\\end{align*} $$\n"]}, {"cell_type": "markdown", "metadata": {"id": "PfNBTP3JupJg"}, "source": ["<!-- JPN -->\n", "\u4e0a\u8a18\u306e\u5f0f\u304b\u3089\u308f\u304b\u308b\u3088\u3046\u306b\u3001 **MSE \u306f\u4e8c\u4e57\u5024\u304c\u305d\u306e\u307e\u307e\u51fa\u529b\u3055\u308c\u308b**\u3053\u3068\u306b\u6ce8\u610f\u305b\u3088\u3002\n", "\n", "\u3000\u307e\u305f\u3001\u3053\u308c\u3089\u3068\u306f\u5225\u306b\u3001\u76f8\u95a2\u4fc2\u6570 $r$ \u3084\u6c7a\u5b9a\u4fc2\u6570 $r^2$ \u304c\u4f7f\u308f\u308c\u308b\u3053\u3068\u3082\u591a\u3044\u3002\u3053\u306e\u8ab2\u984c\u3067\u306f\u6271\u308f\u306a\u3044\u304c\u3001\u5404\u81ea\u78ba\u8a8d\u3057\u3066\u307b\u3057\u3044\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "-2erTUmhvbEJ"}, "source": ["<!-- ENG -->\n", "As can be seen from the above equation, note that **the MSE outputs the squared value as it is**.\n", "\n", "\u3000Apart from these, the correlation coefficient $r$ and the coefficient of determination $r^2$ are also often used. These are not covered in this assignment, but please check them on your own.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "-1hE2Gsawx5d"}, "outputs": [], "source": ["# define error functions\n", "import numpy as np\n", "def mse(true_y, pred_y):\n", "  return np.mean( (true_y-pred_y)**2 )\n", "def rmse(true_y, pred_y):\n", "  return np.sqrt(mse(true_y, pred_y))\n", "def mae(true_y, pred_y):\n", "  return np.mean( np.abs(true_y-pred_y) )"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "_6gF6iG20TyG"}, "outputs": [], "source": ["mse_val  = mse(test_y, predicted)\n", "rmse_val = rmse(test_y, predicted)\n", "mae_val  = mae(test_y, predicted)\n", "\n", "# {var:.3f} displayes up to 3rd decimal place\n", "# .3 means two numbers from decimal point \n", "# f  means \"for floating point variable (real value)\"\n", "print(f\"mse : {mse_val:.3f}\")\n", "print(f\"rmse: {rmse_val:.3f}\")\n", "print(f\"mae : {mae_val:.3f}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "4HbPPakN32kZ"}, "outputs": [], "source": ["# MSE and MAE are implemented in scikit-learn\n", "from sklearn.metrics import mean_squared_error, mean_absolute_error\n", "\n", "mse_sklearn_val  = mean_squared_error(test_y, predicted)\n", "mae_sklearn_val  = mean_absolute_error(test_y, predicted)\n", "\n", "print(f\"mse: {mse_sklearn_val:.3f}\")\n", "print(f\"mae: {mae_sklearn_val:.3f}\")\n"]}, {"cell_type": "markdown", "metadata": {"id": "SfVxa0146BFC"}, "source": ["-------"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "Q8FQBhCW2P_D"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 3.1\n", "\n", "\u4ea4\u5dee\u691c\u8a3c\u6cd5\u3092\u7528\u3044\u3066\u3001\u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u306b\u5bfe\u3059\u308b\u9069\u5207\u306a\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6c7a\u5b9a\u3057\u3088\u3046\u3002\u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u306e\u7d9a\u304d\u3092\u8a18\u8ff0\u3059\u308b\u3053\u3068\u3067\u3001\u8a13\u7df4\u30c7\u30fc\u30bf\u3092\u7528\u3044\u305f**5-fold \u4ea4\u5dee\u691c\u8a3c\u6cd5**\u3092\u884c\u3044\u3001**MAE\u3092\u6700\u5c0f\u306b\u3059\u308b**\u30d1\u30e9\u30e1\u30fc\u30bf\u3092 `rf_best_parameters` \u306b\u4ee3\u5165\u305b\u3088\u3002MAE\u3092\u6700\u5c0f\u3068\u3059\u308b\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u63a2\u7d22\u306f `GridSearchCV(..., scoring=\"neg_mean_absolute_error\")` \u3068\u3059\u308b\u3053\u3068\u3067\u5b9f\u73fe\u3067\u304d\u308b\u3002\n", "\n", "\u3000\u63a2\u7d22\u3059\u308b\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3068\u3059\u308b\u3002\u3053\u306e\u8a08\u7b97\u306b\u306f1\u5206\u7a0b\u5ea6\u306e\u6642\u9593\u3092\u8981\u3059\u308b\u306e\u3067\u6ce8\u610f\u305b\u3088\u3002\n", "\n", "|  \u5909\u6570  | \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u7bc4\u56f2  |\n", "| ---- | ---- |\n", "|  `n_estimators` | `10, 20, 50, 100, 200, 500`  |\n", "|  `max_depth`  | `2, 4, 6, 8, 10, 12, 14, 16, 18, 20` |"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "F82HMbp9Y7Wx"}, "source": ["<!-- ENG -->\n", "### Exercise 3.1\n", "\n", "Use the cross-validation method to determine the appropriate hyperparameters for the random forest. By completing the following code, perform the **5-fold cross-validation method** on the training data and assign the parameters to `rf_best_parameters` that **minimizes the MAE** with `GridSearchCV(..., scoring=\"neg_mean_absolute_error\")`. \n", "\n", "Here, the hyperparameters to be explored should be as follows. Note that it will takes a minute.\n", "\n", "| variables | range of parameters |\n", "| ---- | ---- |\n", "| `n_estimators` | `10, 20, 50, 100, 200, 500` |\n", "| `max_depth` | `2, 4, 6, 8, 10, 12, 14, 16, 18, 20` |"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "DYtABpD82unj", "tags": []}, "outputs": [], "source": ["# CODE CELL FOR YOUR ANSWER\n", "\n", "from sklearn.ensemble import RandomForestRegressor\n", "from sklearn.model_selection import GridSearchCV\n", "\n", "rfr = RandomForestRegressor(random_state=0)\n", "\n", "...\n", "rf_best_parameters = ..."]}, {"cell_type": "markdown", "metadata": {"id": "B1R6LzRG6WtM"}, "source": ["-----------"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "L8L1xL78kSp1"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 3.2\n", "\n", "\u8ab2\u984c 3.1 \u3067\u5f97\u3089\u308c\u305f\u6700\u9069\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf `best_n_estimators` \u304a\u3088\u3073 `best_max_depth` \u3092\u7528\u3044\u3066\u3001\u8a13\u7df4\u30c7\u30fc\u30bf\u5168\u4ef6\u3092\u7528\u3044\u3066\u6539\u3081\u3066\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3057\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee MAE (mean absolute error) `test_mae_random_forest` \u3092\u8a08\u7b97\u305b\u3088\uff08MSE\u3067\u306f\u306a\u3044\uff09\u3002**\u5b9f\u884c\u306e\u969b\u306b\u306f `RandomForestRegressor()` \u306b `random_state=0` \u3092\u4e0e\u3048\u308b\u3053\u3068\u3092\u5fd8\u308c\u306a\u3044\u3088\u3046\u306b\u305b\u3088\uff08\u3053\u306e\u5f8c\u306e\u8ab2\u984c\u306b\u5f71\u97ff\u3092\u53ca\u307c\u3059\u53ef\u80fd\u6027\u304c\u3042\u308b\uff09\u3002**"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "MvuBAgJTZX5p"}, "source": ["<!-- ENG -->\n", "### Exercise 3.2\n", "\n", "Using the optimal hyperparameters `best_n_estimators` and `best_max_depth` obtained in exercise 3.1, build the trained model again using all the training data, and calculate the mean absolute error (MAE) `test_mae_random_forest` for the test data (not to calculate MSE). **Don't forget to give `random_state=0` to `RandomForestRegressor()` when you run it (it may affect the following exercises)**."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ["# CODE CELL FOR YOUR ANSWER\n", "\n", "from sklearn.ensemble import RandomForestRegressor\n", "from sklearn.metrics import mean_absolute_error\n", "\n", "best_n_estimators = ...\n", "best_max_depth = ...\n", "\n", "...\n", "test_mae_random_forest = ...\n"]}, {"cell_type": "markdown", "metadata": {"id": "4_J-G_mN6YIZ"}, "source": ["-------------"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "H7Jhau6QZZoF"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 3.3\n", "\n", "\u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u306e\u91cd\u8981\u5ea6\u304c\u9ad8\u304b\u3063\u305f3\u3064\u306e\u7279\u5fb4\u91cf `important_features` \u3092\u7b54\u3048\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "sPy8f7ArZzOJ"}, "source": ["<!-- ENG -->\n", "### Exercise 3.3\n", "\n", "Answer three the most important features `important_features` according to the feature importances of the random forest.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ["# CODE CELL FOR YOUR ANSWER\n", "\n", "import numpy as np\n", "\n", "...\n", "important_features = ...\n"]}, {"cell_type": "markdown", "metadata": {"id": "4mlnycDk7dvc"}, "source": ["------"]}, {"cell_type": "markdown", "metadata": {"id": "ppR-EilHaImK"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 3.4\uff08\u767a\u5c55\uff09\n", "\n", "\u306a\u305c\u305d\u308c\u3089\u306e\u7279\u5fb4\u91cf\u306f\u91cd\u8981\u306a\u306e\u304b\uff1f\uff08\u5909\u6570\u9593\u306e\u76f8\u95a2\u95a2\u4fc2\u3067\u306f\u306a\u304f\uff09\u73fe\u5b9f\u4e16\u754c\u306b\u304a\u3051\u308b\u7406\u7531\u3092\u8003\u5bdf\u305b\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "2A4C0Jh_aC0A"}, "source": ["<!-- ENG -->\n", "### Exercise 3.4 (Advanced)\n", "\n", "Why are those features important? Consider the reasons in the real world (not correlations between variables.)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "FjjM8vcy7eqX"}, "source": ["------"]}, {"cell_type": "markdown", "metadata": {"id": "8AD-Sj1j7Ouj"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 3.5\uff08\u767a\u5c55\uff09\n", "\u4ea4\u5dee\u691c\u8a3c\u6cd5\u4ee5\u5916\u306e\u6700\u826f\u30e2\u30c7\u30eb\u9078\u629e\u65b9\u6cd5\u306f\u5b58\u5728\u3059\u308b\u304b\u3001\u8b70\u8ad6\u305b\u3088\u3002\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u8ffd\u52a0\u5b9f\u9a13\u3092\u884c\u3044\u3001\u8ab2\u984c 3.2\u3067\u5f97\u3089\u308c\u305f\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u7cbe\u5ea6\u3068\u6bd4\u8f03\u3057\u3066\u3082\u826f\u3044\u3002\uff08\u305d\u306e\u5834\u5408\u306f\u9069\u5b9c\u30b3\u30fc\u30c9\u30bb\u30eb\u3092\u8ffd\u52a0\u3057\u3066\u69cb\u308f\u306a\u3044\uff09"]}, {"cell_type": "markdown", "metadata": {"id": "2JVfomgGaNcw"}, "source": ["<!-- ENG -->\n", "### Exercise 3.5 (Advanced)\n", "Discuss whether there is a best model selection method other than the cross-validation. If necessary, you may conduct additional experiments and compare your prediction accuracy with that of the test data obtained in exercise 3.2 (addition of code cells is allowed for this exercise)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "ACqzebzYh8Do"}, "source": ["----------"]}, {"cell_type": "markdown", "metadata": {"id": "_ZCP0M6jwydK"}, "source": ["<!-- JPN -->\n", "## 4 | \u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u2460\uff1a\u7dda\u5f62\u56de\u5e30\u30fb\u591a\u9805\u5f0f\u56de\u5e30\n"]}, {"cell_type": "markdown", "metadata": {"id": "OMPgWhRvkWDL"}, "source": ["<!-- ENG -->\n", "## 4 | Supervised learning 1: Linear and polynomial regression"]}, {"cell_type": "markdown", "metadata": {"id": "ToknqMI4-ilL"}, "source": ["<!-- JPN -->\n", "\u3000\u3053\u306e\u8ab2\u984c\u3067\u306f\u3001\u7dda\u5f62\u56de\u5e30\u3001\u591a\u9805\u5f0f\u56de\u5e30\u3001\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7528\u3044\u305f\u56de\u5e30\u306e3\u3064\u306b\u53d6\u308a\u7d44\u3080\u3002\u3053\u308c\u3089\u306e\u30e2\u30c7\u30eb\u3092\u9069\u5207\u306b\u8a55\u4fa1\u30fb\u6bd4\u8f03\u3059\u308b\u305f\u3081\u306b\u3001\u307e\u305a\u306f\u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u4f5c\u6210\u3092\u884c\u3046\u3002\u3053\u3053\u3067\u306f\u3001\u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u3046\u3061\u3001\u88fd\u9020\u5e74\u304c1978\u5e74\uff5e1979\u5e74\u3067\u3042\u308b\u8eca\u306e\u30c7\u30fc\u30bf\u3092\u691c\u8a3c\u30c7\u30fc\u30bf\u3068\u3057\u3001\u6b8b\u308a\u306e\u8a13\u7df4\u30c7\u30fc\u30bf\u3001\u3059\u306a\u308f\u3061\u88fd\u9020\u5e74\u304c1970\u5e74\uff5e1977\u5e74\u3067\u3042\u308b\u8eca\u306e\u30c7\u30fc\u30bf\u3092\u90e8\u5206\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u547c\u3076\u3053\u3068\u306b\u3059\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "3p8_FBDgxfXJ"}, "source": ["<!-- ENG -->\n", "In this exercise, we will work on three types of regression: linear regression, polynomial regression, and regression using neural networks. In order to properly evaluate and compare these models, we first prepare the validation data. Here, among the training data, we refer to the data of cars whose year of manufacture is 1978-1979 as the validation data, and the rest of the training data, i.e., the data of cars whose year of manufacture is 1970-1977, as the partial training data."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "OBmApsRg_PLz"}, "outputs": [], "source": ["train_sub_X = train_X[train_X[\"Model Year\"] <  78]\n", "train_sub_y = train_y[train_X[\"Model Year\"] <  78]\n", "valid_X     = train_X[train_X[\"Model Year\"] >= 78]\n", "valid_y     = train_y[train_X[\"Model Year\"] >= 78]"]}, {"cell_type": "markdown", "metadata": {"id": "iNElc7xOAU8W"}, "source": ["<!-- JPN -->\n", "\u3000\u3053\u308c\u304b\u3089\u7dda\u5f62\u56de\u5e30\u3092\u884c\u3046\u306e\u3060\u304c\u3001\u305d\u306e\u524d\u306b\u76ee\u7684\u5909\u6570 MPG \u306e\u4e88\u6e2c\u306b\u7dda\u5f62\u56de\u5e30\u304c\u9069\u3057\u3066\u3044\u308b\u306e\u304b\u3069\u3046\u304b\u306b\u3064\u3044\u3066\u691c\u8a0e\u3057\u3088\u3046\u3002\n", "\u7dda\u5f62\u56de\u5e30\u306f\u3001\u5404\u8aac\u660e\u5909\u6570\uff08\u7279\u5fb4\u91cf\uff09\u3068\u76ee\u7684\u5909\u6570\u3068\u306e\u9593\u306b\u7dda\u5f62\u306e\u95a2\u4fc2\u304c\u3042\u308b\u3068\u3044\u3046\u4eee\u5b9a\u306b\u57fa\u3065\u3044\u305f\u30e2\u30c7\u30eb\u3067\u3042\u3063\u305f\u3002\n"]}, {"cell_type": "markdown", "metadata": {"id": "CTfW2xMFyPIp"}, "source": ["<!-- ENG -->\n", "\u3000We will now perform a linear regression, but before that, let us consider whether linear regression is suitable for predicting the objective variable MPG.\n", "Linear regression is a model based on the assumption that there is a linear relationship between each explanatory variable (feature) and the objective variable."]}, {"cell_type": "markdown", "metadata": {"id": "pn9qboEvyP-N"}, "source": ["$$\n", "  \\hat{y} = \\sum_{k=0}^K \\hat{w}_kx_k\n", "$$"]}, {"cell_type": "markdown", "metadata": {"id": "Cgh2GjEPyUhc"}, "source": ["<!-- JPN -->\n", "\u3053\u308c\u306f\u3001\u5404\u8aac\u660e\u5909\u6570\u3068\u76ee\u7684\u5909\u6570\u3068\u306e\u9593\u306b\u975e\u7dda\u5f62\u306a\u95a2\u4fc2\u304c\u3042\u308b\u5834\u5408\u306b\u306f\u3001\u305f\u3068\u3048**\u5909\u6570\u9593\u306b\u975e\u7dda\u5f62\u3060\u304c\u660e\u78ba\u306a\u95a2\u4fc2\u6027\u304c\u3042\u3063\u305f\u3068\u3057\u3066\u3082\u7dda\u5f62\u56de\u5e30\u30e2\u30c7\u30eb\u3067\u306f\u8868\u73fe\u3067\u304d\u306a\u3044**\u3053\u3068\u3092\u610f\u5473\u3059\u308b\u3002\n", "\n", "\u3000\u4ee5\u4e0a\u306e\u8b70\u8ad6\u304b\u3089\u3001\u5404\u8aac\u660e\u5909\u6570\u3068\u76ee\u7684\u5909\u6570\u30922\u8ef8\u3068\u3057\u305f\u6563\u5e03\u56f3\u3092\u63cf\u753b\u3057\u3001\u3053\u308c\u304c\u7dda\u5f62\u306a\u95a2\u4fc2\u306b\u3042\u308b\u304b\u3069\u3046\u304b\u3092\u898b\u308b\u3053\u3068\u3067\u3001\u7dda\u5f62\u56de\u5e30\u306b\u57fa\u3065\u304f\u4e88\u6e2c\u304c\u6a5f\u80fd\u3059\u308b\u304b\u5426\u304b\u306e\u5224\u65ad\u6750\u6599\u306b\u3067\u304d\u308b\u3002\u5b9f\u969b\u306b\u3084\u3063\u3066\u307f\u3088\u3046\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "_ue17108yVhw"}, "source": ["<!-- ENG -->\n", "This means that if there is a nonlinear relationship between each explanatory variable and the objective variable, **it cannot be represented by a linear regression model, even if there is a obvious relationship between the variables**.\n", "\n", "\u3000From the above discussion, by drawing a scatter plot with each explanatory variable and the objective variable as the two axes, and seeing whether or not there is a linear relationship between them, we can use this as a basis for judging whether or not predictions based on linear regression will work. Let's do this."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "jkFXQJiFB58p"}, "outputs": [], "source": ["# draw figures: it's quite difficult...\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "\n", "n_features = len(train_sub_X.columns)\n", "ncols = 4\n", "nrows = int(np.ceil(n_features/ncols))\n", "fig = plt.figure(figsize=(2*ncols, 2*nrows))\n", "\n", "for i, col in enumerate(train_sub_X.columns):\n", "  ax = fig.add_subplot(nrows, ncols, i+1)\n", "  ax.scatter(train_sub_X[col], train_sub_y)\n", "  ax.set_title(col)\n", "  plt.tight_layout()"]}, {"cell_type": "markdown", "metadata": {"id": "etxotXXcE5kC"}, "source": ["<!-- JPN -->\n", "\u5927\u307e\u304b\u306b\u5404\u8aac\u660e\u5909\u6570\u3068\u76ee\u7684\u5909\u6570\u306f\u7dda\u5f62\u306e\u95a2\u4fc2\u3092\u6301\u3064\u3088\u3046\u3060\u304c\u3001\u4e00\u90e8\u306e\u8aac\u660e\u5909\u6570\u306f\u7dda\u5f62\u3068\u306f\u7570\u306a\u308b\u3001\u66f2\u7dda\u7684\u306a\u95a2\u4fc2\u3092\u6301\u3064\u3088\u3046\u3060\u3002\u3053\u308c\u306b\u7559\u610f\u3057\u306a\u304c\u3089\u3001\u4ee5\u4e0b\u306e\u8ab2\u984c\u306b\u53d6\u308a\u7d44\u3093\u3067\u307b\u3057\u3044\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "hix3WaHHzTKI"}, "source": ["<!-- ENG -->\n", "It seems that each explanatory variable and the objective variable have a roughly linear relationship, but some explanatory variables seem to have a non-linear relationship. Please keep this in mind as you work on the following exercise."]}, {"cell_type": "markdown", "metadata": {"id": "Yh5oJgPXFOID"}, "source": ["------"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "4NUXigh4jyCd"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 4.1\n", "\n", "\u90e8\u5206\u8a13\u7df4\u30c7\u30fc\u30bf\u3092\u7528\u3044\u3066\u7dda\u5f62\u56de\u5e30\u4e88\u6e2c\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3057\u3001\u90e8\u5206\u8a13\u7df4\u30c7\u30fc\u30bf\u3001\u691c\u8a3c\u30c7\u30fc\u30bf\u305d\u308c\u305e\u308c\u306b\u5bfe\u3059\u308b\u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee MAE (mean absolute error) `mae_lr_train` \u304a\u3088\u3073 `mae_lr_valid` \u3092\u6c42\u3081\u3088\u3002\u306a\u304a\u3001MAE\u306f `sklearn.metrics.mean_absolute_error()` \u3067\u8a08\u7b97\u304c\u53ef\u80fd\u3067\u3042\u308b\u3002\n"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "9GAO2qu5zU8Y"}, "source": ["<!-- ENG -->\n", "### Exercise 4.1\n", "\n", "Construct a linear regression model using the partial training data, and calculate the mean absolute error (MAE) for the partial training data `mae_lr_train` and the validation data `mae_lr_valid`. MAE can be calculated with `sklearn.metrics.mean_absolute_error()`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ["# CODE CELL FOR YOUR ANSWER\n", "\n", "from sklearn.linear_model import LinearRegression\n", "from sklearn.metrics import mean_absolute_error\n", "\n", "...\n", "mae_lr_train = ...\n", "mae_lr_valid = ..."]}, {"cell_type": "markdown", "metadata": {"id": "z8R4tJFiFM5S"}, "source": ["-----"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "urrhGQi4lM-j"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 4.2\n", "\n", "\u90e8\u5206\u8a13\u7df4\u30c7\u30fc\u30bf\u3092\u7528\u3044\u3066**\u4ea4\u4e92\u4f5c\u7528\u9805\u3092\u542b\u30802\u6b21\u306e\u9805\u307e\u3067\u3092\u5229\u7528\u3057\u305f\u591a\u9805\u5f0f\u56de\u5e30\u4e88\u6e2c\u30e2\u30c7\u30eb**\u3092\u69cb\u7bc9\u3057\u3001\u90e8\u5206\u8a13\u7df4\u30c7\u30fc\u30bf\u3001\u691c\u8a3c\u30c7\u30fc\u30bf\u305d\u308c\u305e\u308c\u306b\u5bfe\u3059\u308b\u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee MAE `mae_pr_train` \u304a\u3088\u3073 `mae_pr_valid` \u3092\u6c42\u3081\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "EPtsxj0Zd8O_"}, "source": ["<!-- ENG -->\n", "### Exercise 4.2\n", "\n", "Construct a **polynomial regression** model using partial training data **up to the second order term including the interaction term**, and calculate the mean absolute error MAE for the partial training data `mae_pr_train` and the validation data `mae_pr_valid`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ["# CODE CELL FOR YOUR ANSWER\n", "\n", "...\n", "mae_pr_train = ...\n", "mae_pr_valid = ..."]}, {"cell_type": "markdown", "metadata": {"id": "TfEd-KFWID-4"}, "source": ["------"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "FDTGQbnBpCnx"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 4.3\n", "\n", "Ridge\u6b63\u5247\u5316\u3092\u5c0e\u5165\u3057\u3001**\u4ea4\u4e92\u4f5c\u7528\u9805\u3092\u542b\u30802\u6b21\u306e\u9805\u307e\u3067\u3092\u5229\u7528\u3057\u305f\u591a\u9805\u5f0fRidge\u56de\u5e30\u4e88\u6e2c\u30e2\u30c7\u30eb**\u3092\u69cb\u7bc9\u3057\u3001\u90e8\u5206\u8a13\u7df4\u30c7\u30fc\u30bf\u3001\u691c\u8a3c\u30c7\u30fc\u30bf\u305d\u308c\u305e\u308c\u306b\u5bfe\u3059\u308b\u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee MAE \u3092\u6c42\u3081\u3088\u3002\u305f\u3060\u3057\u3001Ridge\u56de\u5e30\u306e\u6b63\u5247\u5316\u9805\u306b\u5bfe\u3059\u308b\u91cd\u307f $\\alpha$ \u306f 0.1 \u3068\u305b\u3088\u3002\n", "\u3053\u306e\u969b\u3001 `make_pipeline` \u3092\u7528\u3044\u308b\u3053\u3068\u3067\u3001**Ridge\u56de\u5e30\u3092\u884c\u3046\u76f4\u524d**\u306b\u7279\u5fb4\u91cf\u306e\u6a19\u6e96\u5316\u3092\u884c\u3046\u3053\u3068\u3092\u5fd8\u308c\u306a\u3044\u3088\u3046\u306b\u305b\u3088\u3002\n"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "na3uXuyEeYZf"}, "source": ["<!-- ENG -->\n", "### Exercise 4.3\n", "\n", "Construct a **polynomial Ridge regression** model using partial training data **up to the second order term including the interaction term**, and calculate the mean absolute error MAE for the partial training data and the validation data. Note that the weight $\\alpha$ for the regularization term of Ridge regression should be 0.1.\n", "Do not forget to standardize the features just before performing the Ridge regression by using `make_pipeline`.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ["# CODE CELL FOR YOUR ANSWER\n", "\n", "...\n", "mae_ridge_train = ...\n", "mae_ridge_valid = ...\n"]}, {"cell_type": "markdown", "metadata": {"id": "l4LCMqtqGSH3"}, "source": ["-----"]}, {"cell_type": "markdown", "metadata": {"id": "HMpx4yzXANxm"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 4.4\n", "\n", "Ridge\u56de\u5e30\u306e\u76f4\u524d\u306b\u884c\u3046\u3079\u304d\u64cd\u4f5c\u3067\u3042\u308b **\u6a19\u6e96\u5316 standardization** \u3068\u306f\u3069\u306e\u3088\u3046\u306a\u3082\u306e\u3060\u3063\u305f\u304b\u3002\u4ee5\u4e0b\u306e\u7a7a\u6b04\u306b\u9069\u5207\u306a\u6570\u5024\u3092\u8a18\u5165\u305b\u3088\u3002\n", "\n", "```\n", "\u6a19\u6e96\u5316 standardization \u3068\u306f\u3001\u5404\u7279\u5fb4\u91cf\u306b\u3064\u3044\u3066\u3001\u5e73\u5747 [ ]\u3001\u5206\u6563 [ ] \u306b\u306a\u308b\u3088\u3046\u306b\u5024\u3092\u5909\u63db\u3059\u308b\u64cd\u4f5c\u306e\u3053\u3068\u3092\u6307\u3059\u3002\n", "```"]}, {"cell_type": "markdown", "metadata": {"id": "CXmm7SRZjFPg"}, "source": ["<!-- ENG -->\n", "### Exercise 4.4\n", "\n", "What was **standardization**, the operation that should have been performed just before the Ridge regression? Fill in the blanks below with the appropriate numbers.\n", "\n", "```\n", "Standardization refers to the operation of transforming the values for each feature so that the mean [ ] and variance [ ].\n", "```"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "jEXB_qisFpSk"}, "source": ["----------"]}, {"cell_type": "markdown", "metadata": {"id": "C0wZFdFmlen6"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 4.5\n", "\n", "\u8ab2\u984c 4.1 \uff5e 4.3 \u306e\u7d50\u679c\u304b\u3089\u3001\u3069\u308c\u304c\u300c\u6700\u3082\u826f\u3044\u30e2\u30c7\u30eb\u300d\u3068\u8a00\u3048\u308b\u3060\u308d\u3046\u304b\u3002\n", "\n", "- \u7dda\u5f62\u56de\u5e30\u4e88\u6e2c\u30e2\u30c7\u30eb\n", "- \u591a\u9805\u5f0f\u56de\u5e30\u4e88\u6e2c\u30e2\u30c7\u30eb\n", "- \u591a\u9805\u5f0fRidge\u56de\u5e30\u4e88\u6e2c\u30e2\u30c7\u30eb\n", "- \u6700\u826f\u306f\u6c7a\u5b9a\u3067\u304d\u306a\u3044"]}, {"cell_type": "markdown", "metadata": {"id": "HMU1oJldjlTh"}, "source": ["<!-- ENG -->\n", "### Exercise 4.5\n", "\n", "Based on the results of exercises 4.1-4.3, which of the following is the \"best model\"?\n", "\n", "- Linear regression model.\n", "- Polynomial regression model.\n", "- Polynomial Ridge regression model.\n", "- The best cannot be determined."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "QDZeMGUKqXET"}, "source": ["-------"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "u4CNoIS-pKXX"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 4.6\uff08\u767a\u5c55\uff09\n", "\u4eca\u56de\u306e\u3088\u3046\u306b\u3001\u3042\u3089\u304b\u3058\u3081\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u691c\u8a3c\u30c7\u30fc\u30bf\u3092\u5206\u5272\u3057\u305f\u5834\u5408\u3001 `GridSearchCV()` \u3092\u5358\u7d14\u306b\u5229\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\u3002**\u591a\u9805\u5f0fRidge\u56de\u5e30\u306b\u3064\u3044\u3066**\u3001\u4f55\u3089\u304b\u306e\u65b9\u6cd5\u3092\u7528\u3044\u3066\u3001\u4ee5\u4e0b\u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u7a7a\u9593\uff0821\u901a\u308a\u306e\u7d44\u307f\u5408\u308f\u305b\u304c\u3042\u308b\uff09\u3092\u63a2\u7d22\u3057\u3001**\u691c\u8a3c\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308bMAE\u3092\u6700\u5c0f\u3068\u3059\u308b**\u6700\u9069\u306a\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf `best_p` \u304a\u3088\u3073 `best_alpha` \u3092\u5831\u544a\u305b\u3088\u3002\n", "\n", "|  \u5909\u6570  | \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u7bc4\u56f2  |\n", "| ---- | ---- |\n", "|  \u6b21\u5143\u6570 `p` | `1, 2, 3`  |\n", "|  \u6b63\u5247\u5316\u9805\u306e\u91cd\u307f `alpha`  | `0.001, 0.01, 0.1, 1, 10, 100, 1000` |"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "bcz4m8D7j_DR"}, "source": ["<!-- ENG -->\n", "### Exercise 4.6 (Advanced)\n", "\n", "When the training and validation data are split in advance, as in this case, we cannot simply use `GridSearchCV()`. **For polynomial Ridge regression**, using some method, explore the following hyperparameter space (21 combinations) and report the optimal hyperparameters `best_p` and `best_alpha` **which minimizes MAE for validation data**.\n", "\n", "| Variables | Range of parameters |\n", "| ---- | ---- |\n", "| number of dimensions `p` | `1, 2, 3` |\n", "| weight of the regularization term `alpha` | `0.001, 0.01, 0.1, 1, 10, 100, 1000` |"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ["# CODE CELL FOR YOUR ANSWER\n", "\n", "\n", "best_p = ...\n", "best_alpha = ...\n", "print(best_p, best_alpha)\n"]}, {"cell_type": "markdown", "metadata": {"id": "lPqUk3e5qYwd"}, "source": ["-----"]}, {"cell_type": "markdown", "metadata": {"id": "M8ahFMlNINk5"}, "source": ["<!-- JPN -->\n", "## 5 | \u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u2461\uff1a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u3088\u308b\u56de\u5e30\u4e88\u6e2c"]}, {"cell_type": "markdown", "metadata": {"id": "O_SRHbOFlbme"}, "source": ["<!-- ENG -->\n", "## 5 | Supervised Learning 2: Regression with Neural Networks"]}, {"cell_type": "markdown", "metadata": {"id": "JzkKPbUfITU6"}, "source": ["<!-- JPN -->\n", "\u3000\u57fa\u76e4\u4eba\u5de5\u77e5\u80fd\u6f14\u7fd2\u3067\u306f\u3001\u5206\u985e\u554f\u984c\u306e\u307f\u3092\u7528\u3044\u3066\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b66\u7fd2\u3057\u305f\u304c\u3001\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u56de\u5e30\u554f\u984c\u306b\u9069\u7528\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3042\u308b\u3002\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u3001\u8ab2\u984c\u306b\u89e3\u7b54\u3057\u306a\u304c\u3089\u56de\u5e30\u554f\u984c\u3078\u306e\u9069\u7528\u65b9\u6cd5\u3092\u5b66\u307c\u3046\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "1RGVgzYtleAw"}, "source": ["<!-- ENG -->\n", "\u3000In the Exercise on Fundamental Artificial Intelligence, we learned neural networks only for classification problems, but it is possible to apply neural networks to regression problems. In this section, we will learn how to apply them to regression problems by doing the exercise."]}, {"cell_type": "markdown", "metadata": {"id": "151EVrlfqZlI"}, "source": ["<!-- JPN -->\n", "\u3000\u4ee5\u4e0b\u306b\u30c7\u30fc\u30bf\u306e\u6e96\u5099\u304a\u3088\u3073\u5404\u7a2e\u95a2\u6570\u306e\u6e96\u5099\u3092\u884c\u3046\u3002\u5206\u985e\u4e88\u6e2c\u3067\u306f\u306a\u304f\u56de\u5e30\u4e88\u6e2c\u3092\u884c\u3046\u969b\u306b\u6ce8\u610f\u3059\u3079\u304d\u70b9\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3042\u308b\u3002\n", "\n", "- \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u5165\u529b\u3059\u308b\u7279\u5fb4\u91cf\u306f\u3042\u3089\u304b\u3058\u3081\u6a19\u6e96\u5316\uff08\u3042\u308b\u3044\u306f\u6b63\u898f\u5316\uff09\u3057\u3066\u304a\u304f\uff08\u3053\u308c\u306f\u5206\u985e\u4e88\u6e2c\u3067\u3082\u540c\u69d8\u3067\u3042\u308b\uff09\u3002\n", "- \u5165\u529b\u7279\u5fb4\u91cf\u3001\u51fa\u529b\u7279\u5fb4\u91cf\u5171\u306b `torch.float` \u306b\u3057\u3066\u304a\u304f\u3002\n", "- 1\u3064\u306e\u5024\u3092\u4e88\u6e2c\u3057\u305f\u3044\u306e\u3067\u3001\u51fa\u529b\u306f1\u6b21\u5143\u3068\u3059\u308b\u3002\n", "- \u640d\u5931\u95a2\u6570\u3092 `torch.nn.L1Loss` \u306b\u3059\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "EQIdn7Jpm4PD"}, "source": ["<!-- ENG -->\n", "\u3000In the following, we will prepare the data and various functions. The points to be noted when performing regression prediction instead of classification prediction are as follows.\n", "\n", "- The features to be input to the neural network should be standardized (or normalized) in advance (This should be also true for classification).\n", "- Both input and output features should be `torch.float`.\n", "- The output should be one-dimensional because we want to predict a single value.\n", "- Set the loss function to `torch.nn.L1Loss`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "DYyAvUNNME6b"}, "outputs": [], "source": ["# install livelossplot\n", "!pip install livelossplot"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "5kEts-3XuQKJ"}, "outputs": [], "source": ["# standardization of features\n", "from sklearn.preprocessing import StandardScaler\n", "\n", "ss = StandardScaler()\n", "train_sub_std_X = ss.fit_transform(train_sub_X)\n", "valid_std_X     = ss.transform(valid_X)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "gXrQdohuLSHS"}, "outputs": [], "source": ["# prepare data\n", "import torch\n", "batch_size = 32\n", "\n", "train_X_torch = torch.tensor(train_sub_std_X, dtype=torch.float)\n", "valid_X_torch = torch.tensor(valid_std_X, dtype=torch.float)\n", "\n", "# convert a vector to a matrix by reshape\n", "train_Y_torch = torch.tensor(train_sub_y.reshape(-1, 1), dtype=torch.float)\n", "valid_Y_torch = torch.tensor(valid_y.reshape(-1,1), dtype=torch.float)\n", "\n", "train_dataset = torch.utils.data.TensorDataset(train_X_torch, train_Y_torch)\n", "valid_dataset = torch.utils.data.TensorDataset(valid_X_torch, valid_Y_torch)\n", "\n", "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n", "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "Q4LyjEyzr5oJ"}, "outputs": [], "source": ["def calculate(model, loss_fn, loader, opt=None):\n", "  if opt is None:\n", "    model.eval()\n", "\n", "  whole_loss = 0\n", "  count = len(loader.dataset)\n", "  \n", "  for X, y in loader:\n", "    # X, y = X.cuda(), y.cuda() # Transfer data to the GPU\n", "    y_pred = model(X) # Predict y from X \n", "    \n", "    loss = loss_fn(y_pred, y)  # Calculate the average of the losses in a mini-batch\n", "    whole_loss += loss.item()*len(y) # Calculate the total loss for the entire epoch\n", "    \n", "    # Update weights\n", "    if opt is not None:\n", "      opt.zero_grad()\n", "      loss.backward()\n", "      opt.step()\n", "    \n", "  mean_loss = whole_loss / count\n", "\n", "  if opt is None:\n", "    model.train()\n", "\n", "  return mean_loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "1rIsJSBGKk8l"}, "outputs": [], "source": ["from livelossplot import PlotLosses\n", "def train(model, loss_fn, opt, train_loader, valid_loader, epoch=50):\n", "  liveloss = PlotLosses() # Initialize the drawing\n", "  for i in range(epoch):\n", "    train_loss = calculate(model, loss_fn, train_loader, opt)\n", "    valid_loss = calculate(model, loss_fn, valid_loader)\n", "  \n", "    # Visualize the loss and accuracy values.\n", "    liveloss.update({\n", "        'loss': train_loss,\n", "        'val_loss': valid_loss,\n", "    })\n", "    liveloss.draw()  \n", "  return model # Return the trained model"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "pt67XOnKMNrF"}, "outputs": [], "source": ["torch.manual_seed(0) # Ensure reproducibility of training results\n", "\n", "mlp = torch.nn.Sequential(\n", "    torch.nn.Linear(12, 24),\n", "    torch.nn.ReLU(),\n", "    torch.nn.Linear(24, 1)\n", ")\n", "# mlp.cuda() # Transfer the model to the GPU\n", "\n", "# Prepare loss functions and optimization methods\n", "loss_fn = torch.nn.L1Loss()\n", "optimizer = torch.optim.SGD(mlp.parameters(), lr=0.01)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "V40vjFsTMfu9"}, "outputs": [], "source": ["# Run training\n", "trained_model = train(mlp, loss_fn, optimizer, train_loader, valid_loader, epoch=200)"]}, {"cell_type": "markdown", "metadata": {"id": "3c2ulxzR1_8w"}, "source": ["----"]}, {"cell_type": "markdown", "metadata": {"id": "8C81Dyuhqp3f"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 5.1\uff08\u767a\u5c55\uff09\n", "\u5206\u985e\u554f\u984c\u3067\u306f\u640d\u5931\u95a2\u6570\u306f `BCEWithLogitsLoss` \u3084 `CrossEntropyLoss` \u3092\u7528\u3044\u3066\u3044\u305f\u3002\u4f55\u6545\u56de\u5e30\u554f\u984c\u3067\u306f `L1Loss` \u306a\u3069\u3001\u7570\u306a\u308b\u640d\u5931\u95a2\u6570\u3092\u4f7f\u3046\u5fc5\u8981\u304c\u3042\u308b\u306e\u304b\u8ff0\u3079\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "vxX2SdNroC72"}, "source": ["<!-- ENG -->\n", "### Exercise 5.1 (Advanced)\n", "\n", "In the classification problem, the loss functions were `BCEWithLogitsLoss` and `CrossEntropyLoss`. Discuss why it is necessary to use different loss functions such as `L1Loss` for regression problem."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "pshbF_Fo1_Kc"}, "source": ["----"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "Z7W-pcUrsC-F"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 5.2\n", "\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3066\u3001\u4ee5\u4e0b\u306e\u5024\u3092\u5831\u544a\u305b\u3088\u3002\n", "\n", "- \u90e8\u5206\u8a13\u7df4\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee MAE `mae_mlp_train`\n", "- \u691c\u8a3c\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee MAE `mae_mlp_valid`\n", "- \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee MAE `mae_mlp_test`\n", "\n", "\u306a\u304a\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u6e96\u5099\u306f\u884c\u3063\u3066\u3044\u306a\u3044\u305f\u3081\u3001\u9069\u5b9c\u4e88\u6e2c\u30fb\u8a55\u4fa1\u3092\u884c\u3046\u305f\u3081\u306e\u6e96\u5099\u3092\u305b\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "cyLv_orcobfb"}, "source": ["<!-- ENG -->\n", "### Exercise 5.2\n", "\n", "Using the trained model, report the following values.\n", "\n", "- MAE (mean absolute error) for partial training data `mae_mlp_train`\n", "- MAE for validation data `mae_mlp_valid`\n", "- MAE for test data `mae_mlp_test`\n", "\n", "Note that preparation of the test data has not been done, so prepare for prediction and evaluation."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "etxotXXcE5fe", "tags": []}, "outputs": [], "source": ["# CODE CELL FOR YOUR ANSWER\n", "\n", "# test data preparation\n", "...\n", "\n", "mae_mlp_train = ...\n", "mae_mlp_valid = ...\n", "mae_mlp_test  = ...\n", "print(mae_mlp_train, mae_mlp_valid, mae_mlp_test)"]}, {"cell_type": "markdown", "metadata": {"id": "-gYO1s5c1-iy"}, "source": ["----"]}, {"cell_type": "markdown", "metadata": {"id": "83HXVw9ct9RU"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 5.3\n", "\n", "\u3053\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u306f\u7573\u307f\u8fbc\u307f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af CNN \u3092\u9069\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\uff08\u5229\u7528\u3059\u308b\u3053\u3068\u306f\u4e0d\u9069\u3067\u3042\u308b\uff09\u3002\u305d\u306e\u7406\u7531\u3092\u7c21\u6f54\u306b\u7b54\u3048\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "lz5rYAVfohqO"}, "source": ["<!-- ENG -->\n", "### Exercise 5.3\n", "\n", "The convolutional neural network (CNN) cannot be applied to this data (it is unsuitable to use). Briefly answer the reason."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "w7JzTaqo17iC"}, "source": ["----"]}, {"cell_type": "markdown", "metadata": {"id": "MbDLN28JagjO"}, "source": ["<!-- JPN -->\n", "## 6 | \u81ea\u7531\u8ab2\u984c\n"]}, {"cell_type": "markdown", "metadata": {"id": "y34o2jAHotU7"}, "source": ["<!-- ENG -->\n", "## 6 | Application to your own task\n"]}, {"cell_type": "markdown", "metadata": {"id": "3t2uLT4abZfL"}, "source": ["<!-- JPN -->\n", "### \u8ab2\u984c 6\uff08\u5b9f\u8df5\uff09\n", "\u5404\u81ea\u3067\u6e96\u5099\u3057\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u5bfe\u3057\u3066\u3001\u672c\u6f14\u7fd2\u3067\u5b66\u3093\u3060\u5185\u5bb9\u3084\u305d\u306e\u4ed6\u306e\u6a5f\u68b0\u5b66\u7fd2\u624b\u6cd5\u3092\u7528\u3044\u3066\u4f55\u3089\u304b\u306e\u5b66\u7fd2\u30fb\u4e88\u6e2c\u3092\u884c\u3048\u3002\u63d0\u51fa\u306e\u969b\u306b\u306f**\u65b0\u898f\u306eipynb\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210**\u3057\u3001\u53ef\u80fd\u3067\u3042\u308c\u3070\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306ecsv\u30d5\u30a1\u30a4\u30eb\u3082\u4f75\u305b\u3066\u63d0\u51fa\u305b\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "QSa3Wgx7o72n"}, "source": ["<!-- ENG -->\n", "### Exercise 6 (Practical)\n", "On the dataset you prepared, apply what you learned in this exercise and other machine learning methods to train and predict. When submitting, **create a new ipynb file**, and if possible, submit a csv file of the dataset as well."]}, {"cell_type": "markdown", "metadata": {"id": "JGtKLO13owov"}, "source": ["---"]}], "metadata": {"accelerator": "GPU", "colab": {"collapsed_sections": [], "name": "FA_final_assignment_BOTH.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3.9.12 ('base')", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.12"}, "otter": {"OK_FORMAT": true, "tests": {"q1-1": {"name": "q1-1", "points": 4, "suites": [{"cases": [], "scored": true, "setup": "", "teardown": "", "type": "doctest"}]}, "q2-2": {"name": "q2-2", "points": 4, "suites": [{"cases": [], "scored": true, "setup": "", "teardown": "", "type": "doctest"}]}, "q3-1": {"name": "q3-1", "points": 5, "suites": [{"cases": [], "scored": true, "setup": "", "teardown": "", "type": "doctest"}]}, "q3-2": {"name": "q3-2", "points": 4, "suites": [{"cases": [], "scored": true, "setup": "", "teardown": "", "type": "doctest"}]}, "q3-3": {"name": "q3-3", "points": 3, "suites": [{"cases": [], "scored": true, "setup": "", "teardown": "", "type": "doctest"}]}, "q4-1": {"name": "q4-1", "points": 3, "suites": [{"cases": [], "scored": true, "setup": "", "teardown": "", "type": "doctest"}]}, "q4-2": {"name": "q4-2", "points": 3, "suites": [{"cases": [], "scored": true, "setup": "", "teardown": "", "type": "doctest"}]}, "q4-3": {"name": "q4-3", "points": 2, "suites": [{"cases": [], "scored": true, "setup": "", "teardown": "", "type": "doctest"}]}, "q4-6": {"name": "q4-6", "points": 3, "suites": [{"cases": [], "scored": true, "setup": "", "teardown": "", "type": "doctest"}]}, "q5-2": {"name": "q5-2", "points": 5, "suites": [{"cases": [], "scored": true, "setup": "", "teardown": "", "type": "doctest"}]}}}, "vscode": {"interpreter": {"hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}}, "nbformat": 4, "nbformat_minor": 0}