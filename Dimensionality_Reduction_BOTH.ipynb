{"cells": [{"cell_type": "markdown", "metadata": {"id": "JC1GIAEp8JEq"}, "source": ["<!-- JPN -->\n", "# \u6b21\u5143\u524a\u6e1b"]}, {"cell_type": "markdown", "metadata": {"id": "psuQVvZzK5nX"}, "source": ["<!-- ENG -->\n", "# Dimensionality Reduction"]}, {"cell_type": "markdown", "metadata": {"id": "Yrw_xg43linT"}, "source": ["<!-- JPN -->\n", "\u203b\u672c\u6f14\u7fd2\u8cc7\u6599\u306e\u4e8c\u6b21\u914d\u5e03\u30fb\u518d\u914d\u5e03\u306f\u304a\u65ad\u308a\u81f4\u3057\u307e\u3059\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "VVlZS5YjK5nZ"}, "source": ["<!-- ENG -->\n", "\u203bDistribution or redistribution of these exercise materials without the copyright holder's permission is not permitted."]}, {"cell_type": "markdown", "metadata": {"id": "eCu0zTYzh42j"}, "source": ["<!-- JPN -->\n", "\u3000\u4f8b\u3048\u3070\u3001\u30c7\u30fc\u30bf\u304c $\\boldsymbol{x} = \\left[x_1, \\dots, x_{10000}\\right]$ \u306e10,000\u6b21\u5143\u3067\u3042\u308b\u3068\u3059\u308b\u3068\u3001\u8996\u899a\u7684\u306b\u5404\u30c7\u30fc\u30bf\u304c\u3069\u3046\u6563\u3089\u3070\u3063\u3066\u3044\u308b\u304b\u3001\u3042\u308b\u3044\u306f\u307e\u3068\u307e\u3063\u3066\u3044\u308b\u304b\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u306f\u5f53\u7136\u56f0\u96e3\u3067\u3042\u308b\u3002\u3053\u306e\u3088\u3046\u306a\u9ad8\u6b21\u5143\u306e\u30c7\u30fc\u30bf\u3092\u4f4e\u6b21\u5143\uff08\u4f8b\u3048\u30702\u6b21\u5143\uff09\u3067\u306a\u3093\u3068\u304b\u8868\u73fe\u3057\u3088\u3046\u3068\u3059\u308b\uff08\u6b63\u78ba\u306b\u306f\u300c\u5c04\u5f71\u3059\u308b\u300d\uff09\u3053\u3068\u3067\u3001**\u30c7\u30fc\u30bf\u306e\u53ef\u8996\u5316**\u306b\u5f79\u7acb\u3064\u306e\u304c\u6b21\u5143\u524a\u6e1b\u3067\u3042\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "WGnf5d6QK5nb"}, "source": ["<!-- ENG -->\n", "\u3000For example, if the data is $\\boldsymbol{x} = \\left[x_1, \\dots, x_{10000}\\right]$, which has 10,000 dimensions, it is naturally difficult to visually check how each data item is scattered or grouped. Dimension reduction is a useful way to **visualize data** by trying to somehow represent (or more accurately, \"project\") such high-dimensional data in a lower dimension (e.g., two dimensions)."]}, {"cell_type": "markdown", "metadata": {"id": "ufh8z4el7n40"}, "source": ["<!-- JPN -->\n", "\u3000\u3053\u306e\u8cc7\u6599\u3067\u306f\u3001\u307e\u305a\u6b21\u5143\u524a\u6e1b\u306b\u3088\u308b\u30b5\u30f3\u30d7\u30eb\uff08\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\uff09\u306e\u53ef\u8996\u5316\u306b\u53d6\u308a\u7d44\u3080\u3002\u305d\u308c\u305e\u308c\u306e\u6b21\u5143\u524a\u6e1b\u624b\u6cd5\u304c\u3069\u306e\u3088\u3046\u306a\u7279\u5fb4\u3092\u6301\u3064\u306e\u304b\u3001\u3068\u3044\u3046\u3068\u3053\u308d\u306b\u7740\u76ee\u3057\u306a\u304c\u3089\u5185\u5bb9\u3092\u78ba\u8a8d\u3057\u3066\u307b\u3057\u3044\u3002\n", "\n", "\u3000\u307e\u305f\u3001\u6b21\u5143\u524a\u6e1b\u306f\u3001\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306b\u304a\u3051\u308b**\u30c7\u30fc\u30bf\u30ce\u30a4\u30ba\u306e\u4f4e\u6e1b**\u306b\u3082\u4f7f\u308f\u308c\u308b\u306e\u3067\u3001\u305d\u306e\u5229\u7528\u4f8b\u306b\u3082\u89e6\u308c\u3066\u304a\u304f\u3002\n"]}, {"cell_type": "markdown", "metadata": {"id": "gJ6Dw5Pp7n41"}, "source": ["<!-- ENG -->\n", "\u3000We will use dimensionality reduction methods to visualize the data. I would like you to check the contents of each method, paying attention to the characteristics of each method.\n", "\n", "\u3000Dimensionality reduction is also used to **reduce noise in the data** in supervised learning. Examples of its use are also mentioned."]}, {"cell_type": "markdown", "metadata": {"id": "JJZIEGixsNeU"}, "source": ["<!-- JPN -->\n", "## \u9ad8\u6b21\u5143\u30c7\u30fc\u30bf\u306e\u76ee\u8996\u306e\u96e3\u3057\u3055"]}, {"cell_type": "markdown", "metadata": {"id": "QnJrZWS0K5ni"}, "source": ["<!-- ENG -->\n", "## Difficulties in visualizing high-dimensional data"]}, {"cell_type": "markdown", "metadata": {"id": "HdiLCX5SsSHJ"}, "source": ["<!-- JPN -->\n", "\u3000\u624b\u6cd5\u306e\u8aac\u660e\u306b\u5165\u308b\u524d\u306b\u3001\u3069\u306e\u3088\u3046\u306a\u5834\u5408\u306b\u6b21\u5143\u524a\u6e1b\u304c\u5fc5\u8981\u306b\u306a\u308b\u304b\u3092\u7c21\u5358\u306b\u8003\u3048\u3066\u307f\u3088\u3046\u3002\u3053\u3053\u3067\u306f\u3001\u624b\u66f8\u304d\u6587\u5b57\u30c7\u30fc\u30bf\uff08digits\u30c7\u30fc\u30bf\uff09\u306e\u3046\u3061300\u4ef6\u3092\u7528\u3044\u3066\u8aac\u660e\u3059\u308b\u3002\n"]}, {"cell_type": "markdown", "metadata": {"id": "cE7d7-1-K5nj"}, "source": ["<!-- ENG -->\n", "\u3000Before going into the explanation of the method, let\u2019s briefly consider when dimension reduction is necessary. Here, I will explain the situation by using 300 handwritten character data items (digits data).\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "6e0UbTsz0yir"}, "outputs": [], "source": ["from sklearn import datasets\n", "import matplotlib.pyplot as plt\n", "\n", "num_data = 300\n", "d = datasets.load_digits()\n", "X = d.data[:num_data]\n", "y = d.target[:num_data]"]}, {"cell_type": "markdown", "metadata": {"id": "s1L1U-H0svR_"}, "source": ["<!-- JPN -->\n", "\u3000digits\u30c7\u30fc\u30bf\u306f64\u6b21\u5143\u306e\u6570\u5024\u304b\u3089\u69cb\u6210\u3055\u308c\u3066\u3044\u308b\u304c\u3001\u4eba\u9593\u306f\u5f53\u71364\u6b21\u5143\u4ee5\u4e0a\u306e\u30c7\u30fc\u30bf\u306e\u6563\u3089\u3070\u308a/\u307e\u3068\u307e\u308a \u3092\u76f4\u611f\u7684\u306b\u7406\u89e3\u3059\u308b\u306e\u306f\u56f0\u96e3\u3067\u3042\u308b\u3002\u305d\u306e\u305f\u3081\u3001\u901a\u5e38\u306f**\u30c7\u30fc\u30bf\u3092\u4f55\u3089\u304b\u306e\u5f62\u30672\u6b21\u5143\u306e\u5024\u306b\u5909\u63db\u3057\u3066\u8868\u793a\u3057\u305f\u3044**\u3068\u601d\u3046\u308f\u3051\u3067\u3042\u308b\u3002\n", "\n", "\u3000\u4f8b\u3048\u3070\u4ee5\u4e0b\u306e\u5834\u5408\u3067\u306f\u300164\u6b21\u5143\u306e\u3046\u3061\u300110\u6b21\u5143\u76ee\u306811\u6b21\u5143\u76ee\u306e2\u8ef8\u3092\u4f7f\u3063\u3066\u30c7\u30fc\u30bf\u306e\u6563\u3089\u3070\u308a\u3092\u898b\u3066\u307f\u308b\u3002\u306a\u304a\u3001\u3053\u306e10, 11\u6b21\u5143\u76ee\u3068\u306f\u3001\u4ee5\u4e0b\u306e\u56f3\u306b\u793a\u3057\u305f\u753b\u7d20\u306e\u8272\u3092\u6307\u3057\u3066\u3044\u308b\u3002\n"]}, {"cell_type": "markdown", "metadata": {"id": "5gPMbPYVK5nl"}, "source": ["<!-- ENG -->\n", "\u3000The digits data consists of 64-dimensional numerical values, and it is naturally difficult for humans to intuitively understand the distribution and cohesion of data with more than 4 dimensions. Therefore, we usually want to **convert the data into two-dimensional values in some way and display them**.\n", "\n", "\n", "\n", "\u3000For example, in the following case, let's look at the data distribution using the two axes of the 10th and 11th dimensions of the 64 dimensions. Note that the 10th and 11th dimensions refer to the colors of the pixels shown in the following figure.\n", "\n"]}, {"cell_type": "markdown", "metadata": {"id": "gCtnlQLfr_9s"}, "source": ["<img src=\"https://i.imgur.com/DNoTMPI.png\" alt=\"Figure x\" width=\"50%\">"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "I6eVviynsqpl"}, "outputs": [], "source": ["## Function for 2D visualization of handwritten character data\n", "def plot_digits(X, y, n_labels=10, title=None):\n", "  # plot X/y in 2-dimensions\n", "  plt.figure(figsize=(5,5))\n", "\n", "  # set color palette for plot\n", "  color = [plt.cm.nipy_spectral(i/n_labels, 1) for i in range(n_labels)]\n", "\n", "  # plot by each label\n", "  for i in range(n_labels):\n", "    plt.scatter(X[y==i, 0], X[y==i, 1],\n", "                color=color[i], marker=f\"${i}$\")\n", "  plt.xlabel(\"1st axis\")\n", "  plt.ylabel(\"2nd axis\")\n", "  plt.title(title)\n", "  plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "YXgputboten6"}, "outputs": [], "source": ["# Draw using the 10th and 11th dimensions of all data (300 items)\n", "plot_digits(X[:, [10,11]], y, n_labels=10)"]}, {"cell_type": "markdown", "metadata": {"id": "FT5ZApYMt1L8"}, "source": ["<!-- JPN -->\n", "\u3000\u5024\u304c\u6574\u6570\u5024\u3057\u304b\u3068\u3089\u306a\u3044\u3053\u3068\u3082\u3042\u308a\u7881\u76e4\u306e\u76ee\u306e\u3088\u3046\u306b\u6574\u5217\u3057\u3066\u3044\u308b\u306e\u306f\u826f\u3044\u304c\u3001\u6b8b\u5ff5\u306a\u304c\u3089\u5404\u6587\u5b57\u304c\u30ad\u30ec\u30a4\u306b\u5206\u96e2\u3055\u308c\u3066\u3044\u308b\u3068\u306f\u8a00\u3044\u96e3\u3044\u72b6\u614b\u3067\u3042\u308b\u3053\u3068\u304c\u308f\u304b\u308b\u3002\n"]}, {"cell_type": "markdown", "metadata": {"id": "RialK5IMK5nm"}, "source": ["<!-- ENG -->\n", "\u3000It is a good thing that the values are aligned like a grid because they only take integer values. However, unfortunately, you can see it is difficult to say that each character is neatly separated.\n", "\n"]}, {"cell_type": "markdown", "metadata": {"id": "A307Ukgmv7ho"}, "source": ["<!-- JPN -->\n", "## \u4e3b\u6210\u5206\u5206\u6790 (principal component analysis; PCA)"]}, {"cell_type": "markdown", "metadata": {"id": "Pq8YURw3K5nm"}, "source": ["<!-- ENG -->\n", "## Principal component analysis (PCA)"]}, {"cell_type": "markdown", "metadata": {"id": "FL1Z0k46v_cA"}, "source": ["<!-- JPN -->\n", "\u3000\u307e\u305a\u3001\u6b21\u5143\u524a\u6e1b\u65b9\u6cd5\u306e1\u3064\u3068\u3057\u3066\u3001\u4e3b\u6210\u5206\u5206\u6790 (PCA) \u306b\u89e6\u308c\u308b\u3002\u9577\u3055 $K$ \u306e\u30d9\u30af\u30c8\u30eb\u3067\u3042\u308b\u3088\u3046\u306a\u30c7\u30fc\u30bf $\\boldsymbol{x}_n$ \u3092\u3001\u3088\u308a\u4f4e\u6b21\u5143\u3067\u3042\u308b $r$ \u6b21\u5143\u306e\u30d9\u30af\u30c8\u30eb\u306b\u7dda\u5f62\u5909\u63db\u3059\u308b\u3082\u306e\u3067\u3042\u308b\u3002\n", "\n", "\u3000\u3067\u306f\u3001\u5b9f\u969b\u306bPCA\u3092\u884c\u3044\u3001\u7d50\u679c\u3092\u53ef\u8996\u5316\u3057\u3066\u307f\u3088\u3046\u3002 \u4eca\u56de\u306f2\u6b21\u5143\u306b\u53ef\u8996\u5316\u3059\u308b\u305f\u3081\u3001`n_components=2`\u3092\u6307\u5b9a\u3059\u308b\u3002\n"]}, {"cell_type": "markdown", "metadata": {"id": "YQb2lBstK5nn"}, "source": ["<!-- ENG -->\n", "Principal component analysis (PCA) is one of dimensionality reduction methods, and is a linear transformation of data $\\boldsymbol{x}_n$, such as a vector of length $K$, into a lower dimensional vector of dimension $r$.\n", "\n", "Now, let's actually do PCA and visualize the results. This time, we will specify `n_components=2` to visualize it in two dimensions.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "xW6uxe9AcTCh"}, "outputs": [], "source": ["# prepare PCA\n", "from sklearn.decomposition import PCA\n", "\n", "pca = PCA(n_components=2) # 2 components will be used\n", "pca.fit(X) # obtain principal component\n", "images_map = pca.transform(X) # transform input data using PCA\n", "\n", "plot_digits(images_map, y, n_labels=10)"]}, {"cell_type": "markdown", "metadata": {"id": "xovpUVpgvVL0"}, "source": ["<!-- JPN -->\n", "\u30001 \u3067\u8a66\u3057\u305f\u7d50\u679c\u306b\u6bd4\u3079\u3066\u3001\u6570\u5b57\u3054\u3068\u306e\u584a\u304c\u69cb\u6210\u3067\u304d\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "msfDEefeK5nn"}, "source": ["<!-- ENG -->\n", "\u3000Compared to the results we tried in 1, we can see that we are able to compose chunks of each number."]}, {"cell_type": "markdown", "metadata": {"id": "QsbDTSY_clga"}, "source": ["<!-- JPN -->\n", "\u3000PCA\u3067\u306f\u3001\u5404\u4e3b\u6210\u5206\uff08\u56fa\u6709\u30d9\u30af\u30c8\u30eb\uff09\u306e\u5024\u3092\u898b\u308b\u3053\u3068\u3067\u3001\u3069\u306e\u8aac\u660e\u5909\u6570\u304c\u4e3b\u8981\u306a\u5bc4\u4e0e\u3092\u3057\u3066\u3044\u308b\u304b\u3001\u307e\u305f\u5404\u4e3b\u6210\u5206\u306e\u56fa\u6709\u5024\u304c\u30c7\u30fc\u30bf\u306e\u5206\u6563\u306e\u3069\u308c\u3060\u3051\u306e\u5272\u5408\u3092\u8868\u3057\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\u5b9f\u969b\u306b\u5404\u6210\u5206\u306e\u5bc4\u4e0e\u3092\u898b\u3066\u307f\u3088\u3046\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "UGSCp2wDK5no"}, "source": ["<!-- ENG -->\n", "\u3000With PCA, by looking at the value of each principal component (eigenvector), we can check which explanatory variables are the main contributors and how much of the variance in the data is represented by the eigenvalues of each principal component. Let's take a look at the actual contribution of each component."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "ryaHtUOq_4QK"}, "outputs": [], "source": ["import pandas as pd\n", "pca = PCA(n_components=3).fit(X) # PCA, use 3 components\n", "\n", "columns = range(64)\n", "indexes = [\"PC1\", \"PC2\", \"PC3\"]\n", "components = pca.components_ # get components from PCA result\n", "\n", "print(pd.DataFrame(components, index=indexes, columns=columns))"]}, {"cell_type": "markdown", "metadata": {"id": "gvqQK2kA7n44"}, "source": ["<!-- BOTH -->\n", "----"]}, {"cell_type": "markdown", "metadata": {"id": "lMaOnlQO7n44"}, "source": ["<!-- JPN -->\n", "##### \u8ab2\u984c 1\n", "\n", "\u3000\u4ee5\u4e0b\u306b swiss-roll \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u751f\u6210\u3057\u30013\u6b21\u5143\u7a7a\u9593\u306b\u63cf\u753b\u3059\u308b\u30b3\u30fc\u30c9\u3092\u793a\u3059\u3002swiss-roll \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u306f\u3001\u30c7\u30fc\u30bf\u304c\u3046\u305a\u307e\u304d\u72b6\u306b\u4e26\u3093\u3067\u3044\u308b\u3002\n", "\n", "\u3000\u4e3b\u6210\u5206\u5206\u6790 PCA \u3092 swiss-roll \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u9069\u7528\u3057\u3001\u3046\u305a\u307e\u304d\u3092\u5c55\u958b\u3059\u308b\u3088\u3046\u306b\u306f **\u6a5f\u80fd\u3057\u306a\u3044** \u3053\u3068\u3092\u78ba\u8a8d\u305b\u3088\u3002\u307e\u305f\u3001\u306a\u305c\u305d\u306e\u3088\u3046\u306b\u306a\u308b\u304b\u3092\u8003\u5bdf\u305b\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "9MAj-8vQ7n44"}, "source": ["<!-- ENG -->\n", "##### Exercise 1\n", "\n", "\u3000The following code generates a swiss-role dataset and draws it in 3D space.\n", "\n", "\u3000Apply the principal component analysis (PCA) to the swiss-roll dataset and confirm that it **does not work** to unroll the swirl. Also, discuss why this is the case."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "OLuMDkc87n45"}, "outputs": [], "source": ["# X_sr: 300 data of 3D coordinate\n", "# t_sr: 300 data of coloring value\n", "X_sr, t_sr = datasets.make_swiss_roll(n_samples=300, random_state=42)\n", "\n", "fig = plt.figure(figsize=(6,6))\n", "ax = fig.add_subplot(projection='3d')\n", "ax.view_init(0, -75)\n", "ax.scatter(X_sr.T[0], X_sr.T[1], X_sr.T[2], c=t_sr, s=50)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"id": "FXF89NGE7n45"}, "source": ["<!-- JPN -->\n", "\u306a\u304a\u3001\u3053\u308c\u3089\u306f digits \u30c7\u30fc\u30bf\u3067\u306f\u306a\u3044\u305f\u3081 `plot_digits()` \u95a2\u6570\u3092\u7528\u3044\u308b\u3053\u3068\u306f\u51fa\u6765\u306a\u3044\u3002\u4ee3\u308f\u308a\u306b\u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u3092\u5229\u7528\u305b\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "qvYhSLha7n45"}, "source": ["<!-- ENG -->\n", "Note that the `plot_digits()` function cannot be used since these are not digits data. Use the following code instead."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "YMkoIWXW7n45"}, "outputs": [], "source": ["# example data\n", "example_first  = [0,  1,  2,  3,  4]\n", "example_second = [2,  1,  5,  3,  4]\n", "example_color  = [0,0.1,0.2,0.3,0.4]\n", "\n", "# draw 2D scatter plot\n", "plt.scatter(example_first, example_second, c=example_color)\n", "plt.xlabel(\"1st axis\")\n", "plt.ylabel(\"2nd axis\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# CODE CELL FOR CONFIRMATION\n", "from sklearn.decomposition import PCA\n", "pca = PCA(n_components=2)\n", "..."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "Hqv9obgn7n45"}, "source": ["<!-- BOTH -->\n", "----"]}, {"cell_type": "markdown", "metadata": {"id": "nBnj7eu87n45"}, "source": ["<!-- JPN -->\n", "##### \u8ab2\u984c 2\n", "\u3000\u8ab2\u984c 1\u3067\u793a\u3057\u305f\u3088\u3046\u306a swiss-roll \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u3064\u3044\u3066\u3001\u3046\u305a\u307e\u304d\u306e\u5185\u5074\u3068\u3046\u305a\u307e\u304d\u306e\u5916\u5074\u3092\u5206\u96e2\u3059\u308b\u3053\u3068\u306e\u3067\u304d\u308b\u6b21\u5143\u524a\u6e1b\u624b\u6cd5\u3092 **\u5f8c\u8ff0\u3059\u308b\u30b0\u30e9\u30d5\u57cb\u3081\u8fbc\u307f\u4ee5\u5916\u3067** \u8abf\u3079\u7b54\u3048\u3088\u3002\n", "\n"]}, {"cell_type": "markdown", "metadata": {"id": "yriLs3Ue7n45"}, "source": ["<!-- ENG -->\n", "##### Exercise 2\n", "\u3000For the swiss-roll data set such as the one shown in Exercise 1, search and answer the dimensionality reduction methods, **excluding graph embedding**, that can separate the inside of the spiral from the outside of the spiral.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "50MtOFMm7n46"}, "source": ["<!-- BOTH -->\n", "-----"]}, {"cell_type": "markdown", "metadata": {"id": "p23726vdEPFY"}, "source": ["<!-- JPN -->\n", "## \u6b63\u6e96\u76f8\u95a2\u5206\u6790 (Canonical Correlation Analysis; CCA)"]}, {"cell_type": "markdown", "metadata": {"id": "PAVQUa8XK5nu"}, "source": ["<!-- ENG -->\n", "## Canonical correlation analysis (CCA)"]}, {"cell_type": "markdown", "metadata": {"id": "BFR70eylETTJ"}, "source": ["<!-- JPN -->\n", "\u3000\u4e3b\u6210\u5206\u5206\u6790 (PCA) \u306f**1\u7a2e\u985e\u306e\u30c7\u30fc\u30bf\u304c\u591a\u6570\u5b58\u5728**\u3059\u308b\u5834\u5408\u306b\u3001\u30c7\u30fc\u30bf\u3092\u8868\u3059\u30d9\u30af\u30c8\u30eb\u3084\u3001\u30c7\u30fc\u30bf\u9593\u306e\u975e\u985e\u4f3c\u5ea6\u3092\u5143\u306b\u4f4e\u6b21\u5143\u7a7a\u9593\u3067\u8868\u73fe\u3057\u3088\u3046\u3068\u3059\u308b\u3082\u306e\u3067\u3042\u3063\u305f\u3002\n", "\n", "\u3000\u6b63\u6e96\u76f8\u95a2\u5206\u6790 (CCA) \u306f**\u7d44\u306b\u306a\u3063\u3066\u3044\u308b**2\u7a2e\u985e\u306e\u30c7\u30fc\u30bf\u304c\u591a\u6570\u5b58\u5728\u3059\u308b\u5834\u5408\u306b\u3001\u305d\u308c\u3089\u306e\u30c7\u30fc\u30bf\u3092**\u540c\u3058\u4f4e\u6b21\u5143\u7a7a\u9593\u3067\u8868\u73fe**\u3057\u3088\u3046\u3068\u3059\u308b\u3082\u306e\u3067\u3042\u308b\u3002\n", "\n", "\u30002\u7a2e\u985e\u306e\u30c7\u30fc\u30bf\u306e\u5217 $(\\boldsymbol{x}_1, \\boldsymbol{z}_1), \\ldots, (\\boldsymbol{x}_n, \\boldsymbol{z}_n)$ \u306b\u5bfe\u3057\u3066\u3001**$\\boldsymbol{x}$ \u3068 $\\boldsymbol{z}$ \u306b\u5171\u901a\u3057\u305f**\u4f4e\u6b21\u5143\u8868\u73fe\u3092\u6c42\u3081\u308b\u305f\u3081\u306b\u3001CCA\u3067\u306f\u4ee5\u4e0b\u306e\u6700\u9069\u5316\u554f\u984c\u3092\u89e3\u3044\u3066\u884c\u5217 $A$, $B$ \u3092\u6c42\u3081\u308b\u3002\uff08\u306a\u304a\u3001\u5f8c\u8ff0\u306e\u4f8b\u3067\u53d6\u308a\u6271\u3046\u3088\u3046\u306b\u3001CCA\u3067\u306f2\u7a2e\u985e\u306e\u30c7\u30fc\u30bf $\\boldsymbol{x}$ \u3068 $\\boldsymbol{z}$ \u306e\u6b21\u5143\u6570\u306f\u7b49\u3057\u304f\u306a\u304f\u3066\u3082\u3088\u3044\u3002\uff09"]}, {"cell_type": "markdown", "metadata": {"id": "8qt-yo8oK5nu"}, "source": ["<!-- ENG -->\n", "\u3000PCA is intended to represent **a large number of data of one type** in a low-dimensional space based on vectors representing the data and dissimilarities between the data.\n", "\n", "\u3000Canonical correlation analysis (CCA) is intended to represent a large number of **paired** data **in the same low-dimensional space**.\n", "\n", "\u3000In order to find a low-dimensional representation **common to $\\boldsymbol{x}$ and $\\boldsymbol{z}$** for two columns of data $(\\boldsymbol{x}_1, \\boldsymbol{z}_1), \\ldots, (\\boldsymbol{x}_n, \\boldsymbol{z}_n)$, CCA solves the following optimization problem to obtain matrices $A$, $B$. (As handled in the following example, with CCA, the number of dimensions of the two types of data $\\boldsymbol{x}$ and $\\boldsymbol{z}$ do not have to be equal.)"]}, {"cell_type": "markdown", "metadata": {"id": "HzCTqhRNmfbq"}, "source": ["<!-- BOTH -->\n", "$$\n", "\\min_{A,B}\\frac{1}{n} \\sum_{i=1}^{n}\\|A^T x_i - B^T z_i \\|^2 \\ \\ \\ \\\n", "{\\rm s.t. }\\ \\\n", "\\mathbb{V}[A^T x_i]=\\mathbb{V}[B^T z_i] = I_r\n", "$$"]}, {"cell_type": "markdown", "metadata": {"id": "M-Z1fmqdmhji"}, "source": ["<!-- JPN -->\n", "\u3000\u4f8b\u3048\u3070\u3001$x$, $z$\u304c\u305d\u308c\u305e\u308c1\u6b21\u5143\u306e\u30c7\u30fc\u30bf\u3067\u3001$x$ \u3068 $z$ \u306b\u5171\u901a\u3059\u308b\u30b7\u30b0\u30ca\u30eb $c_i$ \u3068\u3001$x$ \u3068 $z$ \u3067\u76f8\u4e92\u306e\u95a2\u4fc2\u304c\u7121\u304f\u767a\u751f\u3059\u308b\u30ce\u30a4\u30ba $n_i, n'_i$ \u304b\u3089\u69cb\u6210\u3055\u308c\u308b\u3068\u3057\u3088\u3046\u3002\u305f\u3060\u3057\u3001\u30ce\u30a4\u30ba\u306f\u30b7\u30b0\u30ca\u30eb\u306b\u6bd4\u3079\u308b\u3068\u5e7e\u5206\u5f37\u304f\u3001\u7c21\u5358\u306b\u306f\u30b7\u30b0\u30ca\u30eb\u3092\u767a\u898b\u3067\u304d\u306a\u3044\u72b6\u614b\u3092\u8003\u3048\u308b\u3002\n"]}, {"cell_type": "markdown", "metadata": {"id": "b_T32_9fK5nv"}, "source": ["<!-- ENG -->\n", "\u3000For example, suppose that $x$ and $z$ are one-dimensional data, each consisting of a signal $c_i$ common to $x$ and $z$ and noise $n_i, n'_i$ occurring in $x$ and $z$ with no mutual relationship. However, consider a situation where the noise is somewhat stronger than the signal and the signal cannot be easily detected.\n", "\n"]}, {"cell_type": "markdown", "metadata": {"id": "VqsW6b8OovKA"}, "source": ["<!-- BOTH -->\n", "$$\n", "\\left\\{\n", "\\begin{array}{l}\n", "  x_i= \\varepsilon c_i+n_i \\\\\n", "  z_i= \\varepsilon c_i+n'_i \\\\\n", "\\end{array}\n", "\\right.\n", "$$"]}, {"cell_type": "markdown", "metadata": {"id": "e2V4WR25pUDQ"}, "source": ["<!-- JPN -->\n", "$\\varepsilon$ \u306f\u5c0f\u3055\u3044\u5b9a\u6570\u3067\u3042\u308a\u3001\u30b7\u30b0\u30ca\u30eb\u306b\u6bd4\u3079\u3066\u30ce\u30a4\u30ba\u304c\u5f37\u3044\u3053\u3068\u3092\u610f\u5473\u3057\u3066\u3044\u308b\u3002\n", "\n", "\u3000\u3053\u306e\u3088\u3046\u306a\u3068\u304d\u3001**PCA\u3067\u306f\u30ce\u30a4\u30ba $n_i, n_i'$ \u3092\u5f37\u304f\u691c\u51fa\u3057\u3066\u3057\u307e\u3046\u304c\u3001CCA\u306f $c_i$ \u3092\u691c\u51fa\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3042\u308b**\uff08\u5b9f\u969b\u306b\u7591\u4f3c\u30c7\u30fc\u30bf\u3092\u4f7f\u3063\u3066\u5b9f\u9a13\u3057\u3066\u307f\u308b\u3068\u826f\u3044\uff09\u3002\n", "\n"]}, {"cell_type": "markdown", "metadata": {"id": "aCvPI-1yK5nv"}, "source": ["<!-- ENG -->\n", "$\\varepsilon$ is a small constant, meaning that the noise is strong compared to the signal.\n", "\n", "\n", "\n", "\u3000In such cases, **PCA strongly detects the noise $n_i, n_i'$, while CCA can detect $c_i$** (you can actually experiment with pseudo data).\n"]}, {"cell_type": "markdown", "metadata": {"id": "8M-mWywlydmK"}, "source": ["<!-- JPN -->\n", "### CCA\u306e\u5b9f\u884c\n", "\n", "\u3000\u4eca\u56de\u306f\u3001\u8b1b\u7fa9\u3067\u884c\u3063\u305f\u3082\u306e\u3068\u540c\u69d8\u306b\u3001\u624b\u66f8\u304d\u6587\u5b57\u753b\u50cf\u3092\u4e0a\u4e0b\u306b\u5206\u5272\u3057\u3001\u3053\u306e\u5206\u5272\u3055\u308c\u305f\u30c7\u30fc\u30bf\u5bfe\u306b\u5bfe\u3057\u3066CCA\u3092\u9069\u7528\u3001\u305d\u308c\u3089\u304c\u95a2\u9023\u4ed8\u3051\u3089\u308c\u308b\u304b\u3069\u3046\u304b\u3092\u78ba\u8a8d\u3059\u308b\u3002\u3053\u3053\u3067\u306f\u753b\u50cf\u306e\u4e0a\u90e848\u6b21\u5143\u3092 $\\boldsymbol{x}$\u3001\u4e0b\u90e816\u6b21\u5143\u3092 $\\boldsymbol{z}$ \u3068\u3059\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "1ggpa5lAK5nv"}, "source": ["<!-- ENG -->\n", "### Executing CCA\n", "\n", "\u3000This time, we will split the handwritten text image into upper and lower parts, as we did in the lecture, and apply CCA to the split data pairs to see if they can be associated. Here, the upper 48 dimensions of the image are $\\boldsymbol{x}$ and the lower 16 dimensions are $\\boldsymbol{z}$."]}, {"cell_type": "markdown", "metadata": {"id": "jya7DiOQqU1B"}, "source": ["<img src=\"https://i.imgur.com/xP3OAuI.png\" alt=\"digits split\" width=\"70%\"></img>"]}, {"cell_type": "markdown", "metadata": {"id": "EkN0Tvd7qG6J"}, "source": ["<!-- JPN -->\n", "**digits\u30c7\u30fc\u30bf\u306e\u5206\u5272** \u524d\u8ff0\u3057\u305f\u3088\u3046\u306b\u3001CCA\u3067\u306f $\\boldsymbol{x}$ \u3068 $\\boldsymbol{z}$ \u306e\u6b21\u5143\u6570\u306f\u7b49\u3057\u304f\u306a\u304f\u3066\u3082\u3088\u3044\u3002\n"]}, {"cell_type": "markdown", "metadata": {"id": "PL_6A5mZK5nv"}, "source": ["<!-- ENG -->\n", "**Splitting the digits data** As mentioned above, the number of dimensions of $\\boldsymbol{x}$ and $\\boldsymbol{z}$ do not have to be equal in CCA.\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "4Mprx_wkIMe0"}, "outputs": [], "source": ["num_data = 300\n", "d = datasets.load_digits()\n", "D = d.data[:num_data]\n", "y = d.target[:num_data]\n", "\n", "X = D[:, :48] # 0...47\n", "Z = D[:, 48:] # 48...63"]}, {"cell_type": "markdown", "metadata": {"id": "mork3Txjttdo"}, "source": ["<!-- JPN -->\n", "\u7d9a\u3044\u3066\u3001`X`, `Z` \u3092\u753b\u50cf\u3067\u306f\u306a\u304f\u300c\u6570\u5024\u306e\u7f85\u5217\u300d\u3068\u3057\u3066\u8003\u3048\u3066\u6b63\u6e96\u76f8\u95a2\u5206\u6790\u3092\u5b9f\u884c\u3059\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "mj0WrseEK5nw"}, "source": ["<!-- ENG -->\n", "Next, CCA is performed by considering `X` and `Z` as a \"sequence of numbers\" rather than images."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "j-vwAXFot6QJ"}, "outputs": [], "source": ["# Think of it as a series of numbers, not images.\n", "print(\"X[0] =\", X[0])\n", "print(\"Z[0] =\", Z[0])"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "vxNooTXAKj9w"}, "outputs": [], "source": ["# Perform CCA based on X and Z, and optimize matrices A and B\n", "from sklearn.cross_decomposition import CCA\n", "cca = CCA(n_components=2, scale=True)\n", "cca.fit(X, Z)"]}, {"cell_type": "markdown", "metadata": {"id": "8d0ulu7srR-q"}, "source": ["<!-- JPN -->\n", "\u3053\u308c\u3067\u3001CCA\u306e\u884c\u5217 $A$, $B$ \u306e\u6700\u9069\u5316\u304c\u884c\u308f\u308c\u305f\u3002\u6559\u5e2b\u306a\u3057\u5b66\u7fd2\u3092\u884c\u3063\u305f\u969b\u306e\u30c7\u30fc\u30bf\u3092\u5165\u529b\u3057\u3066\u307f\u3088\u3046\u3002\n", "\n"]}, {"cell_type": "markdown", "metadata": {"id": "6g8hjUj1K5nw"}, "source": ["<!-- ENG -->\n", "Now the matrices $A$ and $B$ of the CCA have been optimized. Let's input the data from the unsupervised learning.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "K12bdSXKB_Ga"}, "outputs": [], "source": ["Xc, Zc = cca.transform(X, Z)\n", "plot_digits(Xc, y, title=\"Xc\")\n", "plot_digits(Zc, y, title=\"Zc\")"]}, {"cell_type": "markdown", "metadata": {"id": "KFYyUpK-D8nq"}, "source": ["<!-- JPN -->\n", "\u3000\u5b9f\u884c\u7d50\u679c\u304b\u3089\u3001$X$\u3068$Z$\u304c\u540c\u4e00\u306e\u7279\u5fb4\u7a7a\u9593\u306b\u5c04\u5f71\u3055\u308c\u3066\u304a\u308a\u3001\u5bfe\u5fdc\u95a2\u4fc2\u306b\u3042\u308b $\\boldsymbol{x}_i$ \u3068 $\\boldsymbol{z}_i$ \u304c\u7279\u5fb4\u7a7a\u9593\u5185\u3067\u8fd1\u63a5\u3057\u3001\u307e\u305f\u540c\u3058\u6570\u5b57\u306f\u540c\u3058\u3088\u3046\u306a\u4f4d\u7f6e\u306b\u5c04\u5f71\u3055\u308c\u3066\u3044\u308b\u3002\u3053\u306e\u7d50\u679c\u304b\u3089\u3001CCA\u306b\u3088\u3063\u3066\u753b\u50cf\u306e\u4e0a\u90e8\u5206\u3068\u4e0b\u90e8\u5206\u304c\u95a2\u9023\u4ed8\u3051\u3089\u308c\u305f\u4f4e\u6b21\u5143\u8868\u73fe\u304c\u5f97\u3089\u308c\u305f\u3053\u3068\u304c\u308f\u304b\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "62NFzASVK5nx"}, "source": ["<!-- ENG -->\n", "\u3000From the execution results, we can see that $X$ and $Z$ are projected into the same feature space, the corresponding $\\boldsymbol{x}_i$ and $\\boldsymbol{z}_i$ are close to each other</font>, and the same numbers are projected into similar locations. This result shows that CCA has produced a low-dimensional representation of the image with the upper and lower parts associated with it."]}, {"cell_type": "markdown", "metadata": {"id": "-mJPrSoFPQ9L"}, "source": ["<!-- JPN -->\n", "\u3000\u306a\u304a\u3001\u767a\u5c55\u7684\u306a\u4f8b\u3068\u3057\u3066\u3001 [\u6b63\u6e96\u76f8\u95a2\u5206\u6790\u3092\u7528\u3044\u305f\u56f3\u66f8\u63a8\u85a6](https://qiita.com/yanagi3150/items/7c84f7d9200e57436879) \u306e\u8a18\u4e8b\u3092\u4f5c\u6210\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u3055\u3089\u306bCCA\u306e\u7406\u89e3\u3092\u6df1\u3081\u305f\u3044\u5834\u5408\u306b\u306f\u3053\u3061\u3089\u3082\u53c2\u7167\u3057\u3066\u307b\u3057\u3044\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "22O1ss3zPcx3"}, "source": ["<!-- ENG -->\n", "\u3000Additionally, we created a post in Qiita (in Japanese), titled [\"Book Recommendations on CCA\"](https://qiita.com/yanagi3150/items/7c84f7d9200e57436879) . So refer to this post if you want to deepen your understanding of CCA."]}, {"cell_type": "markdown", "metadata": {"id": "S65fci3jNgFv"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "Cm2nGGXrESyT"}, "source": ["<!-- JPN -->\n", "##### \u8ab2\u984c 3\n", "\u4ee5\u4e0b\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u7b2c1\u4e3b\u6210\u5206\u306e\u307f\u3092\u53d6\u5f97\u3059\u308bCCA\u3092\u5b9f\u65bd\u3057\u3001$X$ \u3068 $Z$ \u306b\u5171\u901a\u3059\u308b\u95a2\u6570 $\\boldsymbol{c} = \\sin(\\boldsymbol{t})$ \u3068\u3001$X$ \u3092CCA\u306b\u3088\u3063\u3066\u5909\u63db\u3057\u305f $\\hat{\\boldsymbol{c}}_X$ \u306e\u6bd4\u8f03\u3092\u884c\u3046\u3002$\\boldsymbol{c}$ \u3068 $\\hat{\\boldsymbol{c}}_X$ \u306e \u76f8\u95a2\u4fc2\u6570 `c_hat_corrcoef` \u3092\u7b97\u51fa\u3059\u308b\u3053\u3068\u3067\u3001\u305d\u308c\u3089\u304c\u3069\u306e\u7a0b\u5ea6\u985e\u4f3c\u3057\u3066\u3044\u308b\u304b\u78ba\u8a8d\u305b\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "blACFLW0K5nx"}, "source": ["<!-- ENG -->\n", "##### Exercise 3\n", "Perform CCA and obtain only the first principal components for the following data and then calculate the correlation coefficient `c_hat_corrcoef` of projected $X$ ($\\hat{\\boldsymbol{c}}_X$) and the function $\\boldsymbol{c} = \\sin(\\boldsymbol{t})$ which is common to $X$ and $Z$."]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "id": "oxMVnoqA7n48"}, "source": ["<!-- BOTH -->\n", "$$ \\begin{aligned}\n", "\\boldsymbol{t} & = [0,0.01, ... 9.99]   \\\\\n", "\\boldsymbol{c} & = \\sin(\\boldsymbol{t}) \\\\\n", "\\\\\n", "X & =\n", "\\left[\n", "\\begin{array}{l}\n", "  \\boldsymbol{c} + \\frac{\\boldsymbol{t}}{5}      + \\delta \\\\\n", "  \\exp(\\boldsymbol{t}/10) + \\delta \\\\\n", "\\end{array}\n", "\\right] \\\\\n", "Z & =\n", "\\left[\n", "\\begin{array}{l}\n", "  \\delta \\\\\n", "  \\boldsymbol{c} + \\cos(4\\boldsymbol{t}) + \\delta \\\\\n", "\\end{array}\n", "\\right]\n", "\\end{aligned}$$\n"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- JPN -->\n", "\u305f\u3060\u3057\u3001 $\\delta$ \u306f\u5e73\u57470\u3001\u5206\u65631\u306e\u30ac\u30a6\u30b9\u96d1\u97f3 (Gaussian noise) \u3067\u3042\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- ENG -->\n", "where $\\delta$ is Gaussian noise with mean of 0 and variance of 1."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "QOjAtMr_7n48", "tags": []}, "outputs": [], "source": ["import numpy as np\n", "\n", "def gen_data():\n", "  np.random.seed(42)\n", "  length = 10\n", "  delta = 0.01\n", "\n", "  t = np.arange(0, length, delta)\n", "  c = np.sin(t)\n", "\n", "  X = np.vstack([\n", "    c + t/5      + np.random.normal(size=len(t)),\n", "    np.exp(t/10) + np.random.normal(size=len(t))\n", "  ]).T\n", "\n", "  Z = np.vstack([\n", "    np.random.normal(size=len(t)),\n", "    c + np.cos(t*4) + np.random.normal(size=len(t))\n", "  ]).T\n", "\n", "\n", "  return c, X, Z"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "ZX76k-l97n48", "tags": []}, "outputs": [], "source": ["sine_wave, X, Z = gen_data()\n", "\n", "fig = plt.figure(figsize=(8,4))\n", "ax_x = fig.add_subplot(211)\n", "ax_z = fig.add_subplot(212)\n", "\n", "for i in range(X.shape[1]):\n", "  ax_x.plot(X[:,i], label=f'X_{i+1}')\n", "ax_x.legend(loc='upper right')\n", "\n", "for i in range(Z.shape[1]):\n", "  ax_z.plot(Z[:,i], label=f'Z_{i+1}')\n", "ax_z.legend(loc='upper right')\n", "\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ["# CODE CELL FOR YOUR ANSWER\n", "\n", "import numpy as np\n", "from sklearn.cross_decomposition import CCA\n", "\n", "...\n", "c_hat_corrcoef = ..."]}, {"cell_type": "markdown", "metadata": {"id": "NvvfUtyXNi03"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "9HU25s52cmCX"}, "source": ["<!-- JPN -->\n", "### CCA\u306b\u3088\u308b\u753b\u50cf\u306e\u5fa9\u5143\uff08\u767a\u5c55\uff09\n", "\n", "  \u4e3b\u6210\u5206\u5206\u6790 (PCA) \u304a\u3088\u3073\u6b63\u6e96\u76f8\u95a2\u5206\u6790 (CCA) \u306f\u3044\u305a\u308c\u3082\u7dda\u5f62\u5909\u63db\u3092\u884c\u3046\u3082\u306e\u3067\u3042\u308b\u305f\u3081\u3001\u7dda\u5f62\u5909\u63db\u3092\u8868\u3059\u884c\u5217\u306e\u9006\u884c\u5217\u3068\u306e\u884c\u5217\u7a4d\u3092\u3068\u308b\u3053\u3068\u3067\u3001\u753b\u50cf\u3092\u5fa9\u5143\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3042\u308b\u3002\n", "  \u3053\u3053\u3067\u306f\u3001CCA\u3092\u7528\u3044\u3066\u4f4e\u6b21\u5143\u5316\u3057\u305f\u753b\u50cf\u3092\u5fa9\u5143\u3057\u3066\u307f\u3088\u3046\u3002\n"]}, {"cell_type": "markdown", "metadata": {"id": "r8RyYezbK5nx"}, "source": ["<!-- ENG -->\n", "### Image recovery using CCA (Advanced)\n", "\n", "Both of principal component analysis (PCA) and canonical correlation analysis (CCA) reduce dimensions with linear transformation. Thus, we can reconstruct an image by multiplying inverse matrix. Let\u2019s try to recover an image that has been reduced the dimensionality by using CCA.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "Q0u-2t8scwKd"}, "outputs": [], "source": ["# prepare dataset\n", "num_data = 300\n", "d = datasets.load_digits()\n", "D = d.data[:num_data]\n", "y = d.target[:num_data]\n", "\n", "X = D[:, :48] # 0...47  feature\n", "Z = D[:, 48:] # 48...63 feature\n", "\n", "# prepare one test image\n", "image_index = 0\n", "X_test = D[image_index, :48].reshape(1, -1)\n", "Z_test = D[image_index, 48:].reshape(1, -1)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "qkICLwm8dBWc"}, "outputs": [], "source": ["# projection and inverse-projection by CCA\n", "from sklearn.cross_decomposition import CCA\n", "cca = CCA(n_components=16, scale=True)\n", "cca.fit(X, Z)\n", "Xc, Zc = cca.transform(X, Z)\n", "\n", "X_test_map, Z_test_map = cca.transform(X_test, Z_test)\n", "X_recovered_from_X = cca.inverse_transform(X_test_map)\n", "X_recovered_from_Z = cca.inverse_transform(Z_test_map)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "GgSn3Bl7foV6"}, "outputs": [], "source": ["# plot 3 images\n", "X_test_image = X_test.reshape(6, 8)\n", "X_recovered_from_X_image = X_recovered_from_X.reshape(6, 8)\n", "X_recovered_from_Z_image = X_recovered_from_Z.reshape(6, 8)\n", "\n", "plt.figure(figsize=(15, 5))\n", "plt.subplot(1, 3, 1)\n", "plt.imshow(X_test_image)\n", "plt.title(\"Unprocessed image (upper part)\")\n", "\n", "plt.subplot(1, 3, 2)\n", "plt.imshow(X_recovered_from_X_image)\n", "plt.title(\"recovered_from_X\")\n", "\n", "plt.subplot(1, 3, 3)\n", "plt.imshow(X_recovered_from_Z_image)\n", "plt.title(\"recovered_from_Z\")\n", "\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"id": "3dpLzzPohouO"}, "source": ["<!-- JPN -->\n", "\u4e0a\u306e3\u30bb\u30eb\u3092\u5b9f\u884c\u3059\u308b\u3068\u4e09\u3064\u306e\u753b\u50cf\u304c\u51fa\u3066\u304f\u308b\u3002\n", "\n", "\u5de6\u304b\u3089\u3001\u305d\u308c\u305e\u308c\u5143\u306e\u753b\u50cf\u306e\u4e0a\u5074\u3001\u4e0a\u5074\u3092\u5909\u63db\u30fb\u9006\u5909\u63db\u3057\u3066\u4e0a\u5074\u3092\u5fa9\u5143\u3057\u305f\u3082\u306e\u3001\u4e0b\u5074\u3092\u5909\u63db\u30fb\u9006\u5909\u63db\u3057\u3066\u4e0a\u5074\u3092\u5fa9\u5143\u3057\u305f\u3082\u306e\u3067\u3042\u308b\u3002\n", "\n", "`image_index`\u3084`n_components`\u3092\u5909\u66f4\u3057\u3066\u3044\u304f\u3064\u304b\u306e\u4f8b\u3092\u8a66\u3057\u3066\u307f\u3088\u3046\u3002\n", "CCA\u306b\u3088\u3063\u3066\u753b\u50cf\u306e\u4e0a\u5074\u3068\u4e0b\u5074\u3092\u95a2\u9023\u4ed8\u3051\u308b\u3053\u3068\u306b\u3088\u308a\u3001\u753b\u50cf\u306e\u4e0b\u5074\u304b\u3089\u4e0a\u5074\u3092\u3042\u308b\u7a0b\u5ea6\u306e\u7cbe\u5ea6\u3067\u5fa9\u5143\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u306b\u306a\u3063\u305f\u3002\n"]}, {"cell_type": "markdown", "metadata": {"id": "EbL3BUbZK5ny"}, "source": ["<!-- ENG -->\n", "If you run the three cells above, you will get three images.\n", "\n", "From left to right, the upper side of the original image, the upper side which is recovered by transforming and inverse transforming the upper side, and the upper side which is recovered by transforming and inverse transforming the lower side, respectively.\n", "\n", "Let's try a few examples by changing `image_index` and `n_components`.\n", "By associating the upper and lower sides of the image using CCA, it is now possible to recover the upper side from the lower side of the image with some accuracy.\n"]}, {"cell_type": "markdown", "metadata": {"id": "LMo3zo3X7n49"}, "source": ["<!-- BOTH -->\n", "<img src=https://i.imgur.com/a2mY8UK.png width=500px>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["----"]}, {"cell_type": "markdown", "metadata": {"id": "SvLuQycZ71UW"}, "source": ["<!-- JPN -->\n", "## \u30b0\u30e9\u30d5\u57cb\u3081\u8fbc\u307f (Graph Embedding)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "## Graph Embedding"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "\u3000\u3082\u30461\u3064\u306e\u6b21\u5143\u524a\u6e1b\u624b\u6cd5\u3068\u3057\u3066\u3001\u30b0\u30e9\u30d5\u57cb\u3081\u8fbc\u307f (Graph Embedding) \u306b\u3064\u3044\u3066\u8a66\u3057\u3066\u307f\u3088\u3046\u3002\u3053\u306e\u624b\u6cd5\u306f\u3001\u30c7\u30fc\u30bf\u9593\u306e\u95a2\u4fc2\u3092\u30ce\u30fc\u30c9\uff08\u9802\u70b9\u3001node\uff09\u3068\u30a8\u30c3\u30b8\uff08\u679d\u3001\u8fba\u3001edge\uff09\u3067\u8868\u73fe\u3057\u3001 **\u300c\u30a8\u30c3\u30b8\u304c\u5f35\u3089\u308c\u3066\u3044\u308b2\u3064\u306e\u30ce\u30fc\u30c9 $i, j$ \u306f\u4e00\u5b9a\u306e\u985e\u4f3c\u95a2\u4fc2\u304c\u3042\u308b\u300d** \u3068\u3044\u3046\u3053\u3068\u306b\u57fa\u3065\u3044\u3066\u4f4e\u6b21\u5143\u7a7a\u9593\u306b\u5c04\u5f71\u3059\u308b\u3002\n", "\u3053\u306e\u624b\u6cd5\u306f **\u975e\u7dda\u5f62\u306a\u6b21\u5143\u524a\u6e1b\u3092\u5b9f\u73fe** \u3067\u304d\u3066\u304a\u308a\u3001\u305f\u3068\u3048\u3070\u4e3b\u6210\u5206\u5206\u6790 PCA \u3084\u6b63\u6e96\u76f8\u95a2\u5206\u6790 CCA \u3088\u308a\u3082\u8907\u96d1\u306a\u6b21\u5143\u524a\u6e1b\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u308b\u3002\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000Let's try another dimensionality reduction method, Graph Embedding (GE). This method projects data into a low-dimensional space based on data relationship graph, which nodes represent data points and **edges represent similarity relationship between nodes (datapoints) $i, j$**.This method is capable of **non-linear dimensionality reduction** and can perform more complex dimensionality reduction than, for example, PCA or CCA."]}, {"cell_type": "markdown", "metadata": {"id": "wMleuHax_vkl"}, "source": ["<!-- JPN -->\n", "\u3000\u30b0\u30e9\u30d5\u57cb\u3081\u8fbc\u307f\u306f\u3001\u300c\u30a8\u30c3\u30b8\u304c\u5f35\u3089\u308c\u3066\u3044\u308b2\u3064\u306e\u30ce\u30fc\u30c9 $i,j$ \u304c\u3001\u4f4e\u6b21\u5143\u7a7a\u9593\u3067\u3082\u8fd1\u304f\u306b\u5b58\u5728\u3057\u3066\u307b\u3057\u3044\u300d\u306e\u3067\u3001\u4ee5\u4e0b\u306e\u6700\u9069\u5316\u554f\u984c\u3092\u89e3\u304f\u3053\u3068\u3067\u9054\u6210\u3055\u308c\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000Since \"two nodes $i,j$ that are edged should be close together, even in low-dimensional space,\" it is accomplished by solving the following optimization problem."]}, {"cell_type": "markdown", "metadata": {"id": "lduyTRhTABeI"}, "source": ["<!-- BOTH -->\n", "$$\n", "\\min_{z_1, \\dots, z_n} \\sum_{i,j}w_{ij}\\|z_i - z_j \\|^2 \\ \\ \\ \\\n", "{\\rm s.t. }\\ \\\n", "Z^TDZ=I\n", "$$"]}, {"cell_type": "markdown", "metadata": {"id": "MV4qNtM2BGay"}, "source": ["<!-- JPN -->\n", "\u3000\u305f\u3060\u3057\u3001$W=(w_{ij})$ \u306f\u30b0\u30e9\u30d5\u306e\u30a8\u30c3\u30b8\u3092\u96a3\u63a5\u884c\u5217\u3067\u8868\u3057\u305f\u3082\u306e\u3067\u3042\u308a\u3001$D=(d_{ij})$ \u306f\u5bfe\u89d2\u6210\u5206 $d_{ii} = \\sum_jw_{ij}$ \u304b\u3089\u306a\u308b\u5bfe\u89d2\u884c\u5217\u3067\u3042\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000where $W=(w_{ij})$ is the adjacency matrix of the graph and $D=(d_{ij})$ is the diagonal matrix with diagonal components $d_{ii} = \\sum_jw_{ij}$."]}, {"cell_type": "markdown", "metadata": {"id": "VvZ1FSU4_b0c"}, "source": ["<!-- JPN -->\n", "\u3000\u305d\u308c\u3067\u306f\u3001\u5148\u8ff0\u3057\u305f swiss-roll dataset \u3092\u4f7f\u3063\u3066\u3001\u30b0\u30e9\u30d5\u57cb\u3081\u8fbc\u307f\u304c\u3069\u306e\u3088\u3046\u306b\u6a5f\u80fd\u3059\u308b\u306e\u304b\u3001\u898b\u3066\u307f\u3088\u3046\u3002\u3053\u3053\u3067\u306f\u3001\u30b0\u30e9\u30d5\u306e\u96a3\u63a5\u884c\u5217 $W$ \u306e\u5404\u6210\u5206 $w_{ij}$ \u306b\u3064\u3044\u3066\u3001**\u30ce\u30fc\u30c9 $i$ \u306b\u3064\u3044\u3066\u3001\u30e6\u30fc\u30af\u30ea\u30c3\u30c9\u8ddd\u96e2\u304c\u6700\u3082\u8fd1\u30445\u3064\u306e\u30ce\u30fc\u30c9 $j_1, ..., j_5$ \u306b\u5bfe\u3057\u3066\u30a8\u30c3\u30b8\u3092\u5f35\u308b\uff08$w_{ij}=1$ \u306b\u3059\u308b\uff09** \u3053\u3068\u306b\u3057\u3088\u3046\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000Now let's see how the graph embedding works with the swiss-roll dataset described above. Here, we assume that **each node $i$ has edges to five nearest nodes $j_1, ..., j_5$ ($w_{ij_k}=1$) in terms of euclidean distance**.  "]}, {"cell_type": "markdown", "metadata": {"id": "aQmEyMgyDBo0"}, "source": ["<!-- JPN -->\n", "\u3000\u307e\u305a\u3001500\u500b\u306e\u70b9\u304b\u3089\u306a\u308bswiss-roll\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3059\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000First, swiss-roll data consisting of 500 points is created."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "u4qoPJa5-NsW"}, "outputs": [], "source": ["# X_sr: 500 data of 3D coordinate\n", "# t_sr: 500 data of coloring value\n", "X_sr, t_sr = datasets.make_swiss_roll(n_samples=500, random_state=42)\n", "\n", "fig = plt.figure(figsize=(6,6))\n", "ax = fig.add_subplot(projection='3d')\n", "ax.view_init(0, -75)\n", "ax.scatter(X_sr.T[0], X_sr.T[1], X_sr.T[2], c=t_sr, s=50)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"id": "fJ6DBRaw-dL5"}, "source": ["<!-- JPN -->\n", "\u3000\u6b21\u306b\u3001500\u500b\u306e\u70b9\u306b\u3064\u3044\u3066\u3001\u6700\u3082\u8fd1\u30445\u3064\u306e\u70b9\u3092\u6c42\u3081\u3066\u3001\u96a3\u63a5\u884c\u5217 $W$ \u3092\u4f5c\u6210\u3059\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000Next, the adjacency matrix $W$ is created by finding the five nearest points for each of the 500 points."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "YIcSnoZ4DcJC"}, "outputs": [], "source": ["from scipy.spatial.distance import pdist, squareform\n", "\n", "# Calculate the distances between all pairs of node\n", "distance_matrix = squareform(pdist(X_sr))\n", "\n", "# Find the 5 nearest node\n", "# omit the nearest node since it is itself\n", "NUM_NEAREST = 5\n", "nearest_indices = np.argsort(distance_matrix, axis=1)[:, 1:1+NUM_NEAREST]\n", "\n", "# Create adjacency matrix\n", "adjacency_matrix = np.zeros(distance_matrix.shape)\n", "for i, nearest_nodes in enumerate(nearest_indices):\n", "  for node in nearest_nodes:\n", "    adjacency_matrix[i, node] = 1\n", "    adjacency_matrix[node, i] = 1 # symmetric matrix"]}, {"cell_type": "markdown", "metadata": {"id": "HdeMIhj_FqYo"}, "source": ["<!-- JPN -->\n", "\u3000\u3053\u306e\u30b3\u30fc\u30c9\u306b\u3088\u3063\u3066\u3001\u96a3\u63a5\u884c\u5217 $W$ \u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u305f\u306e\u3067\u3001\u30b0\u30e9\u30d5\u57cb\u3081\u8fbc\u307f `SpectralEmbedding()` \u3092\u5b9f\u969b\u306b\u5229\u7528\u3057\u3066\u307f\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000We have created the adjacency matrix $W$ above, and we can use the graph embedding `SpectralEmbedding()`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "VqKeefoHF_B6"}, "outputs": [], "source": ["from sklearn.manifold import SpectralEmbedding\n", "\n", "se = SpectralEmbedding(n_components=2, affinity=\"precomputed\", random_state=42)\n", "X_sr_transformed = se.fit_transform(adjacency_matrix)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "09xgD1blGSFw"}, "outputs": [], "source": ["plt.scatter(X_sr_transformed[:,0], X_sr_transformed[:,1], c=t_sr)\n", "plt.xlabel(\"1st axis\")\n", "plt.ylabel(\"2nd axis\")\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {"id": "5Mn3pmzaHXII"}, "source": ["<!-- JPN -->\n", "\u3000\u3053\u308c\u3092\u898b\u308b\u3068\u3001\u3057\u3063\u304b\u308a\u3068 swiss-roll \u304c\u5c55\u958b\u3055\u308c\u3001\u30b0\u30e9\u30c7\u30fc\u30b7\u30e7\u30f3\u304c1\u65b9\u5411\u306b\u63c3\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u5206\u304b\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000This figure shows that the swiss-roll is well unrolled and the color gradient is in one direction."]}, {"cell_type": "markdown", "metadata": {"id": "oP59cSH_IENt"}, "source": ["<!-- JPN -->\n", "\u3000\u306a\u304a\u3001\u5b9f\u306f\u3001\u3053\u3053\u307e\u3067\u306e\u51e6\u7406\u306f\u624b\u4f5c\u696d\u3067\u884c\u3046\u5fc5\u8981\u306f\u306a\u3044\u3002\u5358\u306b\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30b3\u30fc\u30c9\u3092\u8a18\u8ff0\u3059\u308b\u3060\u3051\u3067\u3001\u7c21\u5358\u306b\u5b9f\u884c\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000Note that the process so far does not have to be done manually. It can be easily performed with the following code."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "pv_S6Z2FINB_"}, "outputs": [], "source": ["NUM_NEAREST = 5\n", "\n", "# affinity: the criteria to create edges\n", "# n_neighbors counts oneselves, and should be incremented by 1\n", "se = SpectralEmbedding(n_components=2, affinity=\"nearest_neighbors\", n_neighbors=NUM_NEAREST+1, random_state=42)\n", "X_sr_transformed = se.fit_transform(X_sr)\n", "plt.scatter(X_sr_transformed[:,0], X_sr_transformed[:,1], c=t_sr)\n", "plt.xlabel(\"1st axis\")\n", "plt.ylabel(\"2nd axis\")\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {"id": "ih39vtIXJesU"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "iWcA_GrXJbNd"}, "source": ["<!-- JPN -->\n", "##### \u8ab2\u984c 4\uff08\u767a\u5c55\uff09\n", "\u3000\u4e0a\u8a18\u306e\u8ab2\u984c\u306f\u3001 `NUM_NEAREST = 5` \u3067\u884c\u3063\u305f\u304c\u3001\u3053\u308c\u3092 `NUM_NEAREST = 2` \u306b\u3059\u308b\u3068\u7d50\u679c\u304c\u5909\u5316\u3059\u308b\u3002\u30b0\u30e9\u30d5\u57cb\u3081\u8fbc\u307f\u306e\u7d50\u679c\u3084\u3001swiss-roll \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u305d\u306e\u3082\u306e\u3092\u76ee\u8996\u3057\u3001\u306a\u305c\u3053\u306e\u3088\u3046\u306a\u7d50\u679c\u306b\u306a\u3063\u305f\u306e\u304b\u8003\u5bdf\u305b\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "fY3hn18JMQJA"}, "source": ["<!-- ENG -->\n", "##### Exercise 4\n", "The above was performed with `NUM_NEAREST = 5`, but when this is changed to `NUM_NEAREST = 2`, the results change. Examine the results of the graph embedding and visually inspect the swiss-roll dataset itself to discuss why this change in results occurred.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# CODE CELL TO EXAMINE NUM_NEAREST = 2\n", "NUM_NEAREST = 2\n", "se = SpectralEmbedding(n_components=2, affinity=\"nearest_neighbors\", n_neighbors=NUM_NEAREST+1, random_state=42)\n", "X_sr_transformed = se.fit_transform(X_sr)\n", "\n", "...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "IJn5Sxv6Lusb"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "7IgblRd13h0J"}, "source": ["<!-- JPN -->\n", "##### \u8ab2\u984c 5\uff08\u5b9f\u8df5\u3001\u63d0\u51fa\u4e0d\u8981\uff09"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "##### Exercise 5 (Practical, not required to submit)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "\u3000\u3088\u308a\u5b9f\u8df5\u7684\u306a\u30c7\u30fc\u30bf\u3092\u7528\u3044\u3066\u30b0\u30e9\u30d5\u57cb\u3081\u8fbc\u307f\u3092\u7528\u3044\u305f\u53ef\u8996\u5316\u3068\u30c7\u30fc\u30bf\u306e\u89e3\u91c8\u3092\u884c\u3046\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000Let's visualize and interpret data using graph embedding with more practical data."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "\u3000\u4eca\u56de\u7528\u3044\u308b\u30c7\u30fc\u30bf `latlng_data.csv` \u306f\u65e5\u672c\u306e47\u90fd\u9053\u5e9c\u770c\u5e81\u6240\u5728\u5730\u306e\u7def\u5ea6\u7d4c\u5ea6\u306e\u30c7\u30fc\u30bf\u3067\u3042\u308b\u3002\u3053\u306e\u30c7\u30fc\u30bf\u3092\u7528\u3044\u3066\u90fd\u9053\u5e9c\u770c\u9593\u306e\u8fd1\u63a5\u95a2\u4fc2\u3092\u53ef\u8996\u5316\u3059\u308b\u3053\u3068\u3092\u76ee\u6a19\u3068\u3057\u305f\u89e3\u6790\u3092\u884c\u3046\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000The data for this exercise `latlng_data.csv` is the latitude and longitude data of the 47 prefectural capitals of Japan. The goal of this analysis is to visualize the neighborhood relationship between prefectures using this data."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "2GWXuYdjGh21"}, "outputs": [], "source": ["import pandas as pd\n", "df_pref = pd.read_csv(\"latlng_data.csv\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "sVyYzfioGqia"}, "outputs": [], "source": ["df_pref.head()"]}, {"cell_type": "markdown", "metadata": {"id": "Kfd1n13C6rVg"}, "source": ["<!-- JPN -->\n", "`prefecture`\u304c\u90fd\u9053\u5e9c\u770c\u540d\u3001`city`\u304c\u90fd\u9053\u5e9c\u770c\u5e81\u6240\u5728\u5730\u3001`latitude` \u304c\u7def\u5ea6\u3001`longitude`\u304c\u7d4c\u5ea6\u3092\u8868\u3057\u3066\u3044\u308b\u3002\n", "\n", "\u3000\u65e5\u672c\u306e\u90fd\u9053\u5e9c\u770c\u3067\u306f\u305d\u306e\u307e\u307e\u7def\u5ea6\u7d4c\u5ea6\u3092\u7528\u3044\u3066\u3082\u554f\u984c\u306a\u3044\u304c\u3001\u5168\u5730\u7403\u4e0a\u306e\u90fd\u5e02\u3092\u6271\u3046\u3053\u3068\u3092\u60f3\u5b9a\u3057\u3001\u7def\u5ea6\u7d4c\u5ea6\u306e\u60c5\u5831\u3092xyz\u5ea7\u6a19\u306b\u5909\u63db\u3059\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000There are four columns: the names of prefectures `prefecture`, the names of prefectural capitals `city`, the latitude `latitude`, and the longitude `longitude`.\n", "\n", "\u3000For Japanese prefectures, there is no problem using latitude and longitude as they are, but assuming that we are dealing with cities on the entire globe, the latitude and longitude information is converted to 3D coordinates `x`, `y`, and `z` by below code."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "5j2Op9vGx_qn"}, "outputs": [], "source": ["import numpy as np\n", "\n", "def latlng2xyz(lat, lon):\n", "    # Convert latitude and longitude information to x, y, z coordinates\n", "    phi = lat * (np.pi/180)\n", "    theta = lon * (np.pi/180)\n", "    x = np.cos(phi) * np.cos(theta)\n", "    y = np.cos(phi) * np.sin(theta)\n", "    z = np.sin(phi)\n", "\n", "    return x, y, z\n", "\n", "# Add x, y, z coordinates to the dataframe df_pref\n", "df_pref[\"x\"], df_pref[\"y\"], df_pref[\"z\"] = latlng2xyz(\n", "    df_pref[\"latitude\"].values,\n", "    df_pref[\"longitude\"].values)\n", "\n", "print(df_pref.head())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "\u30003\u6b21\u5143\u5ea7\u6a19 `x, y, z`\u3092\u30b0\u30e9\u30d5\u57cb\u3081\u8fbc\u307f\u3092\u7528\u3044\u30662\u6b21\u5143\u306b\u4f4e\u6b21\u5143\u5316\u3057\u3001\u53ef\u8996\u5316\u305b\u3088\u3002\u3053\u306e\u969b\u3001\u4e0a\u306e\u6f14\u7fd2\u3067\u884c\u3063\u305f\u3082\u306e\u3068\u540c\u69d8\u306b\u3001\u5404\u30c7\u30fc\u30bf\u70b9\u304b\u3089\u6700\u3082\u8fd1\u3044$k$\u500b\u306e\u70b9\u3092\u6c42\u3081\u3066\u3001\u96a3\u63a5\u884c\u5217 $W$ \u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000Low-dimensionalize `x, y, z` 3D coordinates to 2 dimensions using graph embedding and visualize them. The adjacency matrix $W$ should be created by computing the nearest $k$ points from each data point, similar to what was done above."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "\u3000\u53ef\u8996\u5316\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u305f\u3089\u3001$k$\u3092\u5909\u5316\u3055\u305b\u306a\u304c\u3089\u65e5\u672c\u5730\u56f3\u3068\u898b\u6bd4\u3079\u3001\u90fd\u9053\u5e9c\u770c\u306e\u8fd1\u63a5\u95a2\u4fc2\u304c\u3069\u306e\u3088\u3046\u306b\u8868\u3055\u308c\u3066\u3044\u308b\u304b\u8003\u5bdf\u305b\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000Compare the output with a map of Japan while changing $k$ and discuss how the neighboring relationship of prefectures is represented."]}, {"cell_type": "markdown", "metadata": {"id": "zIjs_vbS9z1z"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "eVlcbJLMSiDX"}, "source": ["<!-- JPN -->\n", "## \u6b21\u5143\u524a\u6e1b\u3068\u5206\u985e\u4e88\u6e2c\u624b\u6cd5\u306e\u7d44\u307f\u5408\u308f\u305b"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "## Combining dimension reduction and classification prediction"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "\u3000\u6b21\u5143\u524a\u6e1b\u306e\u5229\u7528\u6cd5\u306e\u4e00\u3064\u3068\u3057\u3066\u3001\u9ad8\u6b21\u5143\u306e\u30c7\u30fc\u30bf\u3092\u4e00\u65e6\u6b21\u5143\u524a\u6e1b\u3057\u3001\u305d\u308c\u304b\u3089\u5225\u306e\u6a5f\u68b0\u5b66\u7fd2\u624b\u6cd5\u3092\u9069\u7528\u3059\u308b\u3068\u3044\u3046\u3082\u306e\u304c\u3042\u308b\u3002\u6b21\u5143\u524a\u6e1b\u624b\u6cd5\u306b\u3088\u308a\u3001\u30c7\u30fc\u30bf\u3092\u3046\u307e\u304f\u8868\u73fe\u3059\u308b\u7279\u5fb4\u91cf\u3092\u62bd\u51fa\u3057\u3001\u5c0f\u3055\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u3082\u6c4e\u5316\u6027\u80fd\u306e\u9ad8\u3044\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3059\u308b\u306e\u3067\u3042\u308b\u3002\n", "\n", "\u3000\u3053\u3053\u3067\u306f\u3001digits\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u3046\u3061**300\u4ef6\u306e\u307f\u3092\u8a13\u7df4\u30c7\u30fc\u30bf**\u3068\u3057\u3066\u3001PCA\u3092\u7528\u3044\u3066\u4f4e\u6b21\u5143\u5316\u3092\u884c\u3063\u3066\u5b66\u7fd2\u3057\u305f\u5834\u5408\u306b\u3001\u4e88\u6e2c\u7cbe\u5ea6\u304c\u3069\u306e\u3088\u3046\u306b\u5909\u5316\u3059\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "\u3000One way to use dimension reduction is to reduce the dimensionality of high-dimensional data first and then apply another machine learning method. The dimension reduction extracts the features that represent the data well and creates a model that has high generalization performance even for small data sets.\n", "\n", "\u3000Here, we will confirm how the prediction accuracy changes when **only 300 of the digits data sets are used as training data** and training is performed by lowering the dimensions using PCA."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "zkw4bkCqS_w5"}, "outputs": [], "source": ["from sklearn import datasets\n", "d = datasets.load_digits()\n", "X = d.data\n", "y = d.target"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "KTSB1cUALYEN"}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "# Unlike the last time, use train_test_split() to split the data\n", "# If an integer value is given to the argument train_size instead of a real number,\n", "# only that number of data will be used as training data, and the rest will be used as test data\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=300, random_state=42)\n", "\n", "print(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {"id": "lwQveFDGMByS"}, "source": ["<!-- JPN -->\n", "\u3000\u305d\u308c\u3067\u306f\u3001\u307e\u305a `X_train` \u3060\u3051\u3092\u4f7f\u3063\u3066PCA\u306e\u69cb\u7bc9\u3092\u884c\u3046\u3002\u305d\u306e\u5f8c\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u305f\u3081\u306ePCA\u306e\u5834\u5408\u306b\u306f\u3001 `n_components` \u306e\u5024\u306f\u53ef\u8996\u5316\u306b\u6bd4\u3079\u308b\u3068\u5927\u304d\u76ee\u306e\u5024\u306b\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u304c\u591a\u3044\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "yOk-4hJdK5ny"}, "source": ["<!-- ENG -->\n", "\u3000Let's start by building the PCA using only `X_train`. In the case of using PCA for subsequent machine learning, the value of `n_components` is often set to a larger value than for visualization."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "bXw07J4PMM0O"}, "outputs": [], "source": ["from sklearn.decomposition import PCA\n", "\n", "pca = PCA(n_components=10)\n", "pca.fit(X_train)"]}, {"cell_type": "markdown", "metadata": {"id": "5mFpqaT3O2VK"}, "source": ["<!-- JPN -->\n", "\u3000\u7d9a\u3044\u3066\u3001 `X_train`\u3001`X_test` \u305d\u308c\u305e\u308c\u3092PCA\u3067\u6b21\u5143\u524a\u6e1b\u3059\u308b\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "u3yUMu8PK5nz"}, "source": ["<!-- ENG -->\n", "\u3000Then, `X_train` and `X_test` are dimensionally reduced using PCA."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "am2WdjnYO9bK"}, "outputs": [], "source": ["new_X_train = pca.transform(X_train)\n", "new_X_test  = pca.transform(X_test)"]}, {"cell_type": "markdown", "metadata": {"id": "7UTiK5fMPDlS"}, "source": ["<!-- JPN -->\n", "\u3000\u3053\u3053\u307e\u3067\u304f\u308c\u3070\u3001\u5f8c\u306f\u901a\u5e38\u306e\u6a5f\u68b0\u5b66\u7fd2\u3068\u540c\u69d8\u3067\u3042\u308b\u3002\u3053\u3053\u3067\u306f\u6df1\u3055\u306a\u3069\u3092\u7279\u306b\u5236\u9650\u3057\u306a\u3044\u6c7a\u5b9a\u6728\u3092\u7528\u3044\u308b\u3053\u3068\u306b\u3057\u3066\u307f\u3088\u3046\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "FQ3V4AxuK5nz"}, "source": ["<!-- ENG -->\n", "\u3000Once you get to this point, the rest is just like normal machine learning. Let's use a decision tree with no restrictions especially on depth, etc."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "klQI0AFZPNFu"}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\n", "\n", "# training\n", "dt = DecisionTreeClassifier(random_state=2022)\n", "dt.fit(new_X_train, y_train)\n", "\n", "# prediction\n", "y_pred = dt.predict(new_X_test)\n", "\n", "# evaluation\n", "accuracy = (y_pred == y_test).mean()\n", "print(accuracy)"]}, {"cell_type": "markdown", "metadata": {"id": "6-soI0cDUX8U"}, "source": ["<!-- JPN -->\n", "\u3000\u306a\u304a\u3001\u3053\u306e PCA -> \u6c7a\u5b9a\u6728 \u3068\u3044\u3046\u6d41\u308c\u3082\u3001\u57fa\u76e4AI\u6f14\u7fd2\u3067\u5b66\u3093\u3060 `make_pipeline()` \u3092\u4f7f\u3046\u3053\u3068\u304c\u3067\u304d\u308b\u3002\u540c\u4e00\u306e\u6b63\u89e3\u7387\u304c\u5f97\u3089\u308c\u308b\u3053\u3068\u3092\u78ba\u8a8d\u305b\u3088\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "uSLQwCa8K5nz"}, "source": ["<!-- ENG -->\n", "\u3000This PCA -> decision tree flow can also be done using `make_pipeline()`, which we learned in the Exercises in Fundamentals of Artificial Intelligence. Make sure that you get the same accuracy."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "kMt1WWAaUsLe"}, "outputs": [], "source": ["from sklearn.pipeline import make_pipeline\n", "\n", "# training\n", "pca_dt = make_pipeline(\n", "  PCA(n_components=10),\n", "  DecisionTreeClassifier(random_state=2022)\n", ")\n", "\n", "pca_dt.fit(X_train, y_train)\n", "\n", "# prediction\n", "y_pred = pca_dt.predict(X_test)\n", "\n", "# evaluation\n", "accuracy = (y_pred == y_test).mean()\n", "print(accuracy)"]}, {"cell_type": "markdown", "metadata": {"id": "suyGjhExQEoS"}, "source": ["<!-- JPN -->\n", "\u3000\u6700\u5f8c\u306b\u3001\u6b21\u5143\u524a\u6e1b\u3092\u884c\u308f\u306a\u304b\u3063\u305f\u5834\u5408\u306e\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u6b63\u89e3\u7387\u3068\u6bd4\u8f03\u3057\u3066\u307f\u3088\u3046\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "S85YL1DRK5n0"}, "source": ["<!-- ENG -->\n", "\u3000Lastly, let's compare the accuracy to the test data when no dimension reduction is applied."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "6U8hLkf3QC6S"}, "outputs": [], "source": ["# training\n", "dt = DecisionTreeClassifier(random_state=2022)\n", "dt.fit(X_train, y_train)\n", "\n", "# prediction\n", "y_pred = dt.predict(X_test)\n", "\n", "# evaluation\n", "accuracy = (y_pred == y_test).mean()\n", "print(accuracy)"]}, {"cell_type": "markdown", "metadata": {"id": "sNis92rWQzas"}, "source": ["<!-- JPN -->\n", "\u3000\u308f\u305a\u304b\u3067\u306f\u3042\u308b\u304c\u3001\u6b21\u5143\u524a\u6e1b\u306b\u3088\u3063\u3066\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u6b63\u89e3\u7387\u304c\u5411\u4e0a\u3057\u305f\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u305f\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "t3YDl4v9K5n0"}, "source": ["<!-- ENG -->\n", "\u3000Although only slightly, it was confirmed that the dimension reduction improved the accuracy for the test data."]}, {"cell_type": "markdown", "metadata": {"id": "1aptodwjN2MJ"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "Uzq9uLFTGMB-"}, "source": ["<!-- JPN -->\n", "##### \u8ab2\u984c 6\n", "\u3000`n_components` \u306e\u6570\u30921\u304b\u308910\u307e\u3067\u5909\u52d5\u3055\u305b\u3001\u6b21\u5143\u524a\u6e1b\u3092\u884c\u308f\u306a\u304b\u3063\u305f\u5834\u5408\u306b\u6bd4\u3079\u3066\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u7cbe\u5ea6\u304c\u5411\u4e0a\u3059\u308b `n_components` \u3092\u5217\u6319\u305b\u3088\uff08\u6c7a\u5b9a\u6728\u306b\u306f\u4e0a\u8a18\u306e\u30b3\u30fc\u30c9\u3068\u540c\u69d8\u306b `random_state=42` \u3092\u6307\u5b9a\u3059\u308b\u3053\u3068\uff09\u3002\n"]}, {"cell_type": "markdown", "metadata": {"id": "YDNtMLrAK5n0"}, "source": ["<!-- ENG -->\n", "##### Exercise 6\n", "\u3000Vary the number of `n_components` from 1 to 10, and list the `n_components` that improve the prediction accuracy of the test data compared to the case without dimension reduction (specify `random_state=42` in the decision tree as in the code above).\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}, {"cell_type": "markdown", "metadata": {"id": "2KikozeTN4gT"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "o4nw-yLpOaQJ"}, "source": ["<!-- JPN -->\n", "##### \u8ab2\u984c 7\n", "\u3000\u8ab2\u984c 6\u306e\u7d50\u679c\u306b\u3064\u3044\u3066\u3001\u306a\u305c\u3053\u306e\u3088\u3046\u306a\u7d50\u679c\u306b\u306a\u3063\u305f\u3068\u8003\u3048\u3089\u308c\u308b\u304b\u3001\u300cPCA\u306e\u7d2f\u7a4d\u5bc4\u4e0e\u7387\u300d\u300c\u904e\u5b66\u7fd2\u300d\u300c\u30d0\u30a4\u30a2\u30b9\u3068\u30d0\u30ea\u30a2\u30f3\u30b9\u300d\u300c\u30e2\u30c7\u30eb\u306e\u8907\u96d1\u3055\u300d\u306a\u3069\u306e\u5358\u8a9e\u3092\u9069\u5b9c\u5229\u7528\u3057\u3066\u8003\u5bdf\u305b\u3088\u3002\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u3001\u6c7a\u5b9a\u6728\u306e\u6df1\u3055\u3092\u5236\u9650\u3059\u308b\u306a\u3069\u3057\u3066\u8ffd\u52a0\u306e\u5b9f\u9a13\u3092\u884c\u3063\u3066\u3082\u826f\u3044\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "jWM3_oxCK5n0"}, "source": ["<!-- ENG -->\n", "##### Exercise 7\n", "\u3000Regarding the results of Exercise 6, discuss and explain why you think it happened using wording such as \"cumulative explained variance ratio of PCA,\" \"overfitting,\" \"bias and variance,\" and \"model complexity\" as appropriate. If necessary, additional experiments can be conducted by limiting the depth of the decision tree."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- JPN -->\n", "<font color=orange> **\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u30bb\u30eb\u306b\u7b54\u6848\u3092\u8a18\u8ff0\u305b\u3088\u3002** </font>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- ENG -->\n", "<font color=orange> **Write your answer in this text cell.** </font>"]}], "metadata": {"colab": {"provenance": []}, "kernelspec": {"display_name": "Python 3.9.12 ('base')", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.12"}, "otter": {"OK_FORMAT": true, "tests": {"q3": {"name": "q3", "points": 3, "suites": [{"cases": [], "scored": true, "setup": "", "teardown": "", "type": "doctest"}]}}}, "vscode": {"interpreter": {"hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}}, "nbformat": 4, "nbformat_minor": 0}